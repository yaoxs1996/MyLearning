数据挖掘任务分为：**描述**和**预测**  

[TOC]

# 第2章 认识数据
## 2.1 数据对象与属性类型
### 2.1.1 什么是属性
### 2.1.2 标称属性
### 2.1.3二元属性
一种标称属性
### 2.1.4 序数属性
### 2.1.5 数值属性
1 区间标度属性
2 比率标度属性
具有零点
### 2.1.6 离散属性与连续属性

### 2.4.7 余弦相似性
词频向量  
使用余弦度量作为相似性函数  
余弦值越接近1，夹角越小，向量间的匹配度越大  
$$sim(\vec{x} , \vec{y})=\frac{\vec{x} \cdot \vec{y}}{|\vec{x}||\vec{y}|}$$
$|\vec{x}|$是向量$\vec{x}$的欧几里得范数  

# 第3章 数据预处理
## 3.1 数据预处理：概述
### 3.1.1 数据质量：为什么要对数据预处理
准确性、完整性、一致性
### 3.1.2 数据预处理的主要任务
1. 数据清理
2. 数据集成
3. 数据规约
4. 数据变换
***
## 3.2 数据清理
### 3.2.1 缺失值
### 3.2.2 噪声数据
数据光滑技术：
* 分箱
* 回归
* 离群点分析
### 3.2.3 数据清理作为一个过程
***
## 3.3 数据集成
合并来自多个数据存储的数据。  
### 3.3.1 实体识别问题
模式集成、对象匹配
### 3.3.2 冗余和相关分析
1. **标称数据的卡方相关检测**
2. **数值数据的相关系数**
计算属性A和B的相关系数（Pearson积矩系数）。  
$r_{A,B}$大于零，则A和B正相关；小于零，则负相关；等于0，则A和B独立。  
***相关性并不蕴含因果关系***  
3. **数值数据统计的协方差**
### 3.3.3 元组重复
### 3.3.4 数据值冲突的检测与处理
可能由于表示、尺度或编码的不同。  

## 3.4 数据归约
Data reduction，得到数据集的归约表示。  
### 3.4.1 数据归约策略概述
* **维归约**（dimensionality reduction）：减少所考虑的随机变量或属性的个数。
* **数量归约**（numerosity reduction）：用替代的、较小的数据表现形式替换原数据。
* **数据压缩**（data compression）：变换。无损、有损。
### 3.4.2 小波变换
离散小波变换（DWT）。
### 3.4.3 主成分分析
主成分分析（principal components analysis，PCA）搜索k个最能代表数据的n维正交向量。  
### 3.4.4 属性子集选择
属性子集选择（特征子集选择）：删除不相关或冗余的属性（或维）减少数据量。  
通常使用压缩搜索空间的启发式算法，通过这些算法是典型的**贪心算法**。  
基本启发式方法包括以下技术：  
(1) 逐步向前选择  
(2) 逐步向后删除  
(3) 逐步向前选择和逐步向后删除的组合  
(4) 决策树归约  
某些情况下，可能进行**属性构造**（特征构造）。
### 3.4.5 回归和对数线性模型：参数化数据归约
**线性回归**  
**多元回归**是（简单）线性回归的扩展。  
**对数线性模型**近似离散的多维概率分布。  
### 3.4.6 直方图
直方图使用分箱来近似数据分布。  
### 3.4.7 聚类
聚类技术将数据元组看做对象。将对象划分为群或簇，使得一个簇中的对象相互“相似”，而与其他簇中的对象“相异”。  
### 3.4.8 抽样
允许用数据小得多的随机样本（子集）表示大型数据集。  
* **无放回简单随机抽样**
* **有放回简单随机抽样**
* **簇抽样**
* **分层抽样**
### 3.4.9 数据立方体聚集

## 3.5 数据变换与数据离散化
### 3.5.1 数据变换策略概述
1. **光滑**：去噪声。分箱、回归和聚类。
2. **属性构造**：由给定属性构造新的属性并添加到属性集中。
3. **聚集**
4. **规范化**
5. **离散化**
6. **由标称数据产生概念分层**
### 3.5.2 通过规范化变换数据
* **最小-最大规范化**：对原始数据进行线性变换。
* **z分数（z-score）规范化**
* **小数定标规范化**：移动属性A的值的小数点位置。
### 3.5.3 通过分箱离散化
基于指定的箱个数的自顶向下的分类技术。  
非监督的离散化技术。  
对用户指定的箱个数很敏感。  
### 3.5.4 通过直方图分析离散化
不使用类信息，非监督离散化技术。  
### 3.5.5 通过聚类、决策树和相关分析离散化
### 3.5.6 标称数据的概念分层产生
1. 由用户或专家在模式级显式地说明属性的部分序
2. 通过显式数据分组说明分层结构的一部分
3. 说明属性集但不说明它们的偏序
4. 只说明部分属性集

## 3.6 小结
* **数据质量**
* **数据清理**
* **数据集成**
* **数据归约**
* **数据变换**
* **数据离散化**

---
# 第4章 数据仓库与联机分析处理

## 4.1 数据仓库：基本概念
### 4.1.1 什么是数据仓库
宽泛地讲，数据仓库是一种数据库。  
数据仓库的关键特征：  
* **面向主题的**
* **集成的**：多个异构数据源。
* **时变的**：从历史角度提供信息
* **非易失的**：物理地分离存放数据
### 4.1.2 操作数据库系统与数据仓库的区别
联机操作数据库系统主要任务是执行联机事务和查询处理，称做**联机事务处理**（Online Transaction Processing，OLTP）。  
数据仓库系统在数据分析和决策方面提供服务。称做**联机分析处理**（OnLine Analytical Processing，OLAP）系统。  
### 4.1.3 为什么需要分离的数据仓库
由于数据仓库与操作数据库两种系统中的数据的结构、内容和用法都不同。  
* 数据库是为已知的任务和负载设计的；数据仓库涉及大量数据在汇总级的计算。
* 数据库支持多事务的并发处理，需要并发控制和恢复机制；OLAP查询只需要对汇总和聚集数据记录进行只读访问。
* 数据库一般不维护历史信息，而决策需要历史数据。
### 4.1.4 数据仓库：一种多层体系结构
1. 底层是 __仓库数据库服务器__
2. 中间层是 __OLAP服务器__
3. 顶层是 __前端客户层__
### 4.1.5 数据仓库模型：企业仓库、数据集市和虚拟仓库
* __企业仓库__ ：关于主题的所有信息，提供企业范围内的数据集成。
* __数据集市__ ：数据集市包含企业范围数据的一个子集。对特定用户群有用，范围限于选定的主题。
* __虚拟仓库__ ：数据库上视图的集合。
### 4.1.6 数据提取、变换和装入
后端工具和实用程序功能：
* __数据提取__
* __数据清理__
* __数据变换__
* __装入__
* __刷新__
### 4.1.7 元数据库

---
# 第8章 分类：基本概念

## 8.1 基本概念
### 8.1.1 什么是分类
预测问题：
> 分类：分类器
> 数值预测：预测器、回归分析
### 8.1.2 分类的一般方法
数据分类：学习阶段（建立分类模型）、分类阶段（使用模型预测给定数据的类标号）  
学习阶段：**训练集** 、 **类标号属性** 、 **训练元组**  
**监督学习**
## 8.2 决策树归纳
### 8.2.1 决策树归纳
**迭代二分器**  
贪心（非回溯方法）方法  
算法基本策略：  
> * 参数*D*、*attribute_list*和*Attribute_selection_method*调用该算法。
> *D*：数据分区。训练元组和相应类标号的完全集。  
> *attribute_list*：描述元组属性的列表。  
> *Attribute_selection_method*：选择属性的启发式过程。  
> 属性选择度量，信息增益、基尼指数。  
> * 树从单个结点*N*开始。
> * 如果*D*中的元组都是同一类，则结点*N*变成树叶，并用该类标记它。
> * 否则，算法调用*Attribute_selection_method*确定**分裂准则**。
> * 结点*N*用分裂准则作为结点上的测试。对分类准则的每一个输出，*N*生出一个分支。分裂属性A有如下可能性：  
>     * A是离散的：测试输出直接对于A的已知值。  
>     * A是连续值：使用$A \leq split\_point$和$A > split\_point$。
>     * A是离散必须产生二叉树：测试形如“$A \in S_A?$”。
> * 对于D的每个结果分区上$D_j$上的元组，同样过程，递归形成决策树。
> * 递归终止条件：  
>     * 分区D的所有元组都属于同一类。
>     * 没有剩余属性进一步划分。
>     * 给定的分支没有元组。
> * 返回结果决策树。
### 8.2.2 属性选择度量
1. **信息增益**
选择具有最高信息增益的属性作为结点N的分类属性。
2. **增益率**
用“分裂信息”值将信息增益规范化。  
约束条件：选取的测试的信息增益必须较大。  
3. **基尼指数**
基尼指数度量数据分区或训练元组集D的不纯度。  
4. 其他属性选择度量
### 8.2.3 树剪枝
剪枝方法处理过拟合问题。  
两种常用的剪枝方法：  
**先剪枝**：提前停止树的构建，对树剪枝。  
**后剪枝**：对完全生长的树剪枝。  
### 8.2.4 可伸缩性与决策树归纳
### 8.2.5 决策树归纳的可视化挖掘
## 8.3 贝叶斯分类方法
预测类隶属关系的概率。  
朴素贝叶斯分类法假定一个属性值在给定类上的影响独立于其他属性的值。类条件独立性。  
### 8.3.1 贝叶斯定理
$P(H|X)$ **后验概率**  
$P(H)$ **先验概率**  
贝叶斯定理：  
$$P(H|X)= {{P(X|H)P(H)} \over P(X)}$$
### 8.3.2 朴素贝叶斯分类
## 8.4 基于规则的分类
### 8.4.1 使用IF-THEN规则分类
### 8.4.2 决策树提取规则
规则是**互斥的** 和 **穷举的**  
### 8.4.3 使用顺序覆盖算法的规则归纳
**顺序覆盖算法** 可以直接从训练数据提取IF-THEN规则，不必产生决策树。  
## 8.5 模型的评估与选择
### 8.5.1 评估分类器性能的度量
### 8.5.2 保持方法和随机二次抽样
**保持** 方法：数据被独立划分为两个集合训练集和检验集。训练集导出模型，检验集估计准确率。  
**随机二次抽样** 将保持方法重复k次。  
### 8.5.3 交叉验证
### 8.5.4 自助法
### 8.5.5 使用统计显著性检验选择模型
### 8.5.6 基于成本效益和ROC曲线比较分类器
## 8.6 提高分类准确率的技术
*组合方法*
### 8.6.1 组合分类方法简介
### 8.6.2 装袋
### 8.6.3 提升和AdaBoost
### 8.6.4 随机森林

___
# 第9章 分类：高级方法
**向后传播** 一种神经网络算法  
**支持向量机** 把训练数据变换到更高维空间  
**使用频繁模式分类**  
## 9.1 贝叶斯信念网络
一种概率的图模型。允许表示属性子集之间的依赖关系。用来分类。  
### 9.1.1 概念与机制
信念网络由两个成分定义—— *有向无环图* 和 *条件概率表* 的集合。  
有向无环图的每个节点代表一个随机变量，每条弧表示概率依赖。  
对于每个变量，有一个 **条件概率表** （Conditional Probability Table，CPT）。  
### 9.1.2 训练贝叶斯信念网络

## 9.2 用后向传播分类
一种神经网络学习算法。  
### 9.2.1 多层前馈神经网络
由一个 *输入层* 、一个或多个 *隐藏层* 和一个 *输出层* 组成。  
n层神经网络，不计算输入层。  
网络是 **前馈的** ，因为权重不送回到输入单元或前一层的输出单元。  
网络是 **全连接的** ，每个单元都想下一层的每个单元提供输入。  
### 9.2.2 定义网络拓扑
### 9.2.3 后向传播
对每个训练样本，修改权重使得网络预测和实际目标值之间的均方误差最小。这种修改“后向”进行。  
**初始化权重**：网络的权重和偏倚都被初始化为小随机数。  
**向前传播输入**  
**向后传播误差**  
### 9.2.4 黑盒内部：后向传播和可解释性
网络提取规则和灵敏度分析。  

## 9.3 支持向量机
**支持向量机** （Support Vector Machine，SVM），一种对线性和非线性数据进行分类的方法。**SVM** 是一种算法。  
使用一种非线性映射，把原训练数据映射到较高的维上。  
### 9.3.1 数据线性可分的情况
### 9.3.2 数据非线性可分的情况
扩展线性SVM，得到非线性SVM。  
第一步：用非线性映射把原输入数据变换到较高维空间。  
第二步：在新的空间搜索分离超平面。  

## 9.4 使用频繁模式分类
### 9.4.1 关联分类
关联规则挖掘一个两步过程：*频繁模式挖掘*、*规则产生*。  
第一步搜索反复出现在数据集中的属性-值对的模式。  
第二步分析频繁模式，以便产生关联规则。  
### 9.4.2 基于有区别力的频繁模式分类

## 9.5 惰性学习法（或从近邻学习）
给定一个训练元组时，**惰性学习法** 简单地存储它，一直等待，直到给定一个检验元组。  
在提供训练元组时只做少量工作，而在进行分类或者数值预测时做更多的工作。  
### 9.5.1 k-最近邻分类
“临近性”用距离度量。  
### 9.5.2 基于案例的推理

## 9.6 其他分类方法
### 9.6.1 遗传算法
### 9.6.2 粗糙集方法
### 9.6.3 模糊集方法

## 9.7 关于分类的其他问题
### 9.7.1 多类分类
__一对所有__：给定m个类，训练m个二元分类器。  
__所有对所有__：对 _每一对类_ 学习一个分类器。  
__纠错码__  提高多类分类的准确性。  
### 9.7.2 半监督学习
使用有类标号的数据和无类标号的数据构建分类器。  
__自我训练__ 使用有标号数据建立分类器，使用该分类器对无标号数据添加标号。  
__协同训练__ 两个或多个训练器互教互学。  
### 9.7.3 主动学习
一种迭代的监督学习。  
### 9.7.4 迁移学习
旨在从一个或多个 _源任务_ 提取知识，将这种知识用在 _目标任务_。  
传统的学习方式对每个分类任务建立一个新的分类器。迁移学习为新任务构建分类器时，使用源任务的知识。  

---
# 第10章 聚类分析：基本概念和方法
## 10.1 聚类分析
### 10.1.1 什么是聚类分析
__无监督学习__  
### 10.1.2 对聚类分析的要求
数据挖掘对聚类的典型要求：  
* __可伸缩性__
* __处理不同属性类型的能力__
* __发现任意形状的簇__
* __对于确定输入参数的领域知识要求__
* __处理噪声数据的能力__
* __增量聚类和对输入次序不敏感__
* __聚类高维数据的能力__
* __基于约束的聚类__
* __可解释性和可用性__

比较聚类方法的诸方面：  
* __划分准则__
* __簇的分离性__
* __相似性度量__
* __聚类空间__
### 10.1.3 基本聚类方法概述
__划分方法__ 多数方法基于距离。  
_k-均值_ 和 _k-中心点_  
基于划分的聚类方法：  
* __层次方法__
* __基于密度的方法__
* __基于网格的方法__
## 10.2 划分方法
n个数据对象的数据集D，__划分算法__ 将数据对象组织成k个分区。  
### 10.2.1 k-均值：一种基于形心的技术
以簇内的高相似性和簇间的低相似性为目标。  
_k-均值_ 将簇的形心定义为簇内点的均值。  
对离群点敏感。  
### 10.2.2 k-中心点：一种基于代表对象的技术
__绝对误差标准__  
__围绕中心点划分__ 算法  
## 10.3 层次方法
__层次聚类方法__ 将数据对象组成层次结构或者簇的“树”。  
### 10.3.1 凝聚的与分裂的层次聚类
__凝聚的层次聚类方法__ 使用自底向上的策略。  
__分裂的层次聚类方法__ 使用自顶向下的策略。  
### 10.3.2 算法方法的距离度量
度量两个簇之间的距离。  
4个广泛采用的簇间距离度量方法：  
* __最小距离__
__最近邻聚类算法__ 、__单连接算法__ 、__最小生成树算法__
* __最大距离__
* __均值距离__
* __平均距离__
### 10.3.3 BIRCH：使用聚类特征树的多阶段聚类
_利用层次结构的平衡迭代归约和聚类_（BIRCH）是为大量数值数据聚类设计的。  
### 10.3.4 Chameleon：使用动态建模的多阶段层次聚类
一种层次聚类算法，采用动态建模来确定一对簇之间的相似度。  
1. 簇中对象的连接情况。
2. 簇的临近性。  
### 10.3.5 概率层次聚类
## 10.4 基于密度的方法
发现任意形状的簇。  
### 10.4.1 DBSCAN：一种基于高密度连通区域的基于密度的距离
__密度可达的__  
### 10.4.2 OPTICS：通过点排序识别聚类结构
__核心距离__、__可达距离__  
### 10.4.3 DENCLUE：基于密度分布函数的聚类
## 10.5 基于网格的方法
空间驱动  
### 10.5.1 STING：统计信息网格
### 10.5.2 CLIQUE：一种类似于Apriori的子空间聚类方法
## 10.6 聚类评估
### 10.6.1 估计聚类趋势
__霍普金斯统计量__ 建议空间分布的变量的空间随机性。  
均匀分布不包含有意义的簇。  
### 10.6.2 确定簇数
经验方法：设置簇数p大约是$\sqrt {n \over 2}$。期望情况下，每个簇大约有$\sqrt {2n}$个点。  
__肘方法__ ：增加簇数有助于降低每个簇的簇内方差之和。使用簇内方差和关于簇数的曲线的拐点。  
### 10.6.3 测定聚类质量
1. 外在方法
    * 簇的同质性
    * 簇的完全性
    * 碎布性
    * 小簇保持性
2. 内在方法
__轮廓系数__  

---
# 第11章 高级聚类分析
## 11.1 基于概率的聚类
模糊的或者灵活的簇指派。  
### 11.1.1 模糊簇
