[TOC]

# 第1章 绪论
## 1.1 引言
## 1.2 基于术语
_数据集_  
_示例或样本_  
_属性或特性_  
_属性值_  
_属性空间、样本空间或输入空间_  
_特征向量_：空间中每个点对应一个坐标向量  
$D=\{x_1,x_2,...,x_m\}$表示包含m个示例的数据集。  
每个示例有d个属性描述，$\vec x_i=(x_{i1};x_{i2};...;x_{id})$。  
预测离散值 分类  
预测连续值 回归  
## 1.3 假设空间
归纳（induction），“泛化”（generalization）  
演绎（deduction），“特化”（specialization）  
将学习过程看做一个在所有假设组成的空间中进行搜索的过程，搜索目标是找到与训练集匹配的假设。  
## 1.4 归纳偏好
* __归纳偏好__：机器学习算法在学习过程中对某种类型假设的偏好。  
任何有效的机器学习算法必有其归纳偏好。  
* 引导算法确立偏好的一般性原则：__奥卡姆剃刀__ ，若有多个假设与观察一致，则选最简单的那个。  
* __没有免费午餐__ 定理（NFL定理）：所有问题出现机会相同、或所有问题同等重要的前提下，所有学习算法期望值相同。  
谈论算法的优劣，必须针对具体的学习问题。  
## 1.5 发展历程
## 1.6 应用现状

---
# 第2章 模型评估与选择
## 2.1 经验误差与过拟合
* 训练集上的误差 _训练误差_ 或 _经验误差_。  
* 新样本上的误差 _泛化误差_。  
* 过拟合是ML的关键障碍。
* ML面临NP难。  
## 2.2 评估方法
从数据集中分出训练集和测试集。  
### 2.2.1 留出法
直接将数据基划分为两个互斥的集合。  
尽量保持数据分布的一致性。  
___一般采用若干次随机划分、重复进行实验评估后取平均值作留出法的评估结果___。  
### 2.2.2 交叉验证法
* 数据集划分成k个大小相似的互斥子集。  
* 每个子集尽可能保持数据分布的一致性。  
* 每次用k-1个子集作为训练集、余下的那个子集作为测试集。  
* 最终返回k个测试结果的均值。  
### 2.2.3 自助法
* 以自助采样法为基础。  
* 对数据集D采样生成数据集D'：
    * 每次从D中挑选一个样本，将其拷贝放入D'中，然后再将该样本放回初始数据集D中。  
    * 该过程重复m次，就获得了包含m个样本的D'。
* D中约有36.8%的样本未出现在采样数据集D'中。
* 用D'做测试集。
* 改变了数据集的分布，产生了估计偏差。  
### 2.2.4 调参与最终模型
## 2.3 性能度量
### 2.3.1 错误率与精度
### 2.3.2 查准率、查全率与F1
* 分类结果混淆矩阵

| 真实情况\预测结果 | 正例 | 反例 |
| - | - | - |
| 正例 | TP（真正例） | FN（假反例） |
| 反例 | FP（假正例） | TN（真反例） |
* 查准率P，检索出的信息有多少是用户关心的：  
$$P={TP \over {TP+FP}}$$
* 查全率R，用户感兴趣的信息有多少被检索出来了：  
$$R={TP \over {TP+FN}}$$
* 查准率-查全率曲线 P-R图
学习器A的P-R曲线完全包住了学习器B的曲线，可以认为A的性能高于B。  
平衡点：查准率=查全率时的取值。  
* F1度量：
$$F1={{2 \times P \times R} \over {P+R}}={{2 \times TP} \over {样本总数+TP-TN}}$$
F1度量的一般形式$F_\beta$，定义：
$$F_\beta={{(1+\beta^2) \times P \times R} \over {(\beta^2 \times P)+R}}$$
其中$\beta>0$。$\beta=1$时退化为标准F1；$\beta>1$时，查全率有更大影响；$\beta<1$时，查准率有更大影响。  
### 2.3.3 ROC与AUC
* ROC受试者工作特性
ROC曲线使用真正例率TPR-假正例率FPR：  
$$TPR={{TP} \over {TP+FN}}$$
$$FPR={{FP} \over {TN+FP}}$$
比较学习器的性能，比较ROC曲线下的面积，即AUC（Area Under ROC Curve）。  
### 2.3.4 代价敏感错误率与代价曲线
非均等代价：权衡不同类型错误所造成的不同损失。  
## 2.4 比较检验
### 2.4.1 假设检验
