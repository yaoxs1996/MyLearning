[TOC]

# 第1章 绪论
## 1.1 引言
## 1.2 基于术语
_数据集_  
_示例或样本_  
_属性或特性_  
_属性值_  
_属性空间、样本空间或输入空间_  
_特征向量_：空间中每个点对应一个坐标向量  
$D=\{x_1,x_2,...,x_m\}$表示包含m个示例的数据集。  
每个示例有d个属性描述，$\vec x_i=(x_{i1};x_{i2};...;x_{id})$。  
预测离散值 分类  
预测连续值 回归  
## 1.3 假设空间
归纳（induction），“泛化”（generalization）  
演绎（deduction），“特化”（specialization）  
将学习过程看做一个在所有假设组成的空间中进行搜索的过程，搜索目标是找到与训练集匹配的假设。  
## 1.4 归纳偏好
* __归纳偏好__：机器学习算法在学习过程中对某种类型假设的偏好。  
任何有效的机器学习算法必有其归纳偏好。  
* 引导算法确立偏好的一般性原则：__奥卡姆剃刀__ ，若有多个假设与观察一致，则选最简单的那个。  
* __没有免费午餐__ 定理（NFL定理）：所有问题出现机会相同、或所有问题同等重要的前提下，所有学习算法期望值相同。  
谈论算法的优劣，必须针对具体的学习问题。  
## 1.5 发展历程
## 1.6 应用现状

---
# 第2章 模型评估与选择
## 2.1 经验误差与过拟合
* 训练集上的误差 _训练误差_ 或 _经验误差_。  
* 新样本上的误差 _泛化误差_。  
* 过拟合是ML的关键障碍。
* ML面临NP难。  
## 2.2 评估方法
从数据集中分出训练集和测试集。  
### 2.2.1 留出法
直接将数据基划分为两个互斥的集合。  
尽量保持数据分布的一致性。  