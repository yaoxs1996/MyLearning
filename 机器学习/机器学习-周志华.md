[TOC]

# 第1章 绪论
## 1.1 引言
## 1.2 基于术语
_数据集_  
_示例或样本_  
_属性或特性_  
_属性值_  
_属性空间、样本空间或输入空间_  
_特征向量_：空间中每个点对应一个坐标向量  
$D=\{x_1,x_2,...,x_m\}$表示包含m个示例的数据集。  
每个示例有d个属性描述，$\vec x_i=(x_{i1};x_{i2};...;x_{id})$。  
预测离散值 分类  
预测连续值 回归  
## 1.3 假设空间
归纳（induction），“泛化”（generalization）  
演绎（deduction），“特化”（specialization）  
将学习过程看做一个在所有假设组成的空间中进行搜索的过程，搜索目标是找到与训练集匹配的假设。  
## 1.4 归纳偏好
* __归纳偏好__：机器学习算法在学习过程中对某种类型假设的偏好。  
任何有效的机器学习算法必有其归纳偏好。  
* 引导算法确立偏好的一般性原则：__奥卡姆剃刀__ ，若有多个假设与观察一致，则选最简单的那个。  
* __没有免费午餐__ 定理（NFL定理）：所有问题出现机会相同、或所有问题同等重要的前提下，所有学习算法期望值相同。  
谈论算法的优劣，必须针对具体的学习问题。  
## 1.5 发展历程
## 1.6 应用现状

---
# 第2章 模型评估与选择
## 2.1 经验误差与过拟合
* 训练集上的误差 _训练误差_ 或 _经验误差_。  
* 新样本上的误差 _泛化误差_。  
* 过拟合是ML的关键障碍。
* ML面临NP难。  
## 2.2 评估方法
从数据集中分出训练集和测试集。  
### 2.2.1 留出法
直接将数据基划分为两个互斥的集合。  
尽量保持数据分布的一致性。  
___一般采用若干次随机划分、重复进行实验评估后取平均值作留出法的评估结果___。  
### 2.2.2 交叉验证法
* 数据集划分成k个大小相似的互斥子集。  
* 每个子集尽可能保持数据分布的一致性。  
* 每次用k-1个子集作为训练集、余下的那个子集作为测试集。  
* 最终返回k个测试结果的均值。  
### 2.2.3 自助法
* 以自助采样法为基础。  
* 对数据集D采样生成数据集D'：
    * 每次从D中挑选一个样本，将其拷贝放入D'中，然后再将该样本放回初始数据集D中。  
    * 该过程重复m次，就获得了包含m个样本的D'。
* D中约有36.8%的样本未出现在采样数据集D'中。
* 用D'做测试集。
* 改变了数据集的分布，产生了估计偏差。  
### 2.2.4 调参与最终模型
## 2.3 性能度量
### 2.3.1 错误率与精度
### 2.3.2 查准率、查全率与F1
* 分类结果混淆矩阵

| 真实情况\预测结果 | 正例 | 反例 |
| - | - | - |
| 正例 | TP（真正例） | FN（假反例） |
| 反例 | FP（假正例） | TN（真反例） |
* 查准率P，检索出的信息有多少是用户关心的：  
$$P={TP \over {TP+FP}}$$
* 查全率R，用户感兴趣的信息有多少被检索出来了：  
$$R={TP \over {TP+FN}}$$
* 查准率-查全率曲线 P-R图
学习器A的P-R曲线完全包住了学习器B的曲线，可以认为A的性能高于B。  
平衡点：查准率=查全率时的取值。  
* F1度量：
$$F1={{2 \times P \times R} \over {P+R}}={{2 \times TP} \over {样本总数+TP-TN}}$$
F1度量的一般形式$F_\beta$，定义：
$$F_\beta={{(1+\beta^2) \times P \times R} \over {(\beta^2 \times P)+R}}$$
其中$\beta>0$。$\beta=1$时退化为标准F1；$\beta>1$时，查全率有更大影响；$\beta<1$时，查准率有更大影响。  
### 2.3.3 ROC与AUC
* ROC受试者工作特性
ROC曲线使用真正例率TPR-假正例率FPR：  
$$TPR={{TP} \over {TP+FN}}$$
$$FPR={{FP} \over {TN+FP}}$$
比较学习器的性能，比较ROC曲线下的面积，即AUC（Area Under ROC Curve）。  
### 2.3.4 代价敏感错误率与代价曲线
非均等代价：权衡不同类型错误所造成的不同损失。  
## 2.4 比较检验
### 2.4.1 假设检验

* 二项检验
* t检验

### 2.4.2 交叉验证t检验

### 2.4.3 McNemar检验

检验两学习器的分类结果的差别。

### 2.4.4 Friedman检验与Nemenyi后续检验

在一组数据集上比较多个算法。  

* 基于算法排序的Friedman检验
    * 使用留出法或交叉验证法得到每个算法在每个数据集上的测试结果；
    * 根据性能进行排序；
    * 测试性能相同则平分序值；
    * 使用Friedman检验判断算法性能是否相同。
    
若算法性能显著不同，使用后续检验来进一步区分。常用Nemenyi后续检验。  
Nemenyi检验计算出平均序值差别的临界值域  

$$CD={q_\alpha{\sqrt {{k(k+1)} \over {6N}}}}$$

若两算法的平均序值之差超出临界值域CD，则以相应的置信度拒绝“两个算法性能相同”这一假设。  

## 2.5 偏差与方差

_偏差-方差分解_ 是解释学习算法泛化性能的一种重要工具。  
泛化误差可以分解成偏差、方差和噪声之和。  
_偏差_ 度量了学习算法本身的拟合能力；  
_方差_ 刻画了数据扰动所造成的影响；  
_噪声_ 刻画了学习问题本身的难度。  

# 第3章 线性模型

## 3.1 基本形式

给定由d个属性描述的$\vec x=(x_1;x_2;...;x_d)$  
线性模型视图学得一个通过属性的线性组合进行预测的函数：

$$f(\vec x)=w_1x_1+w_2x_2+...+w_dx_d+b$$

向量形式：

$$f(\vec x)=\vec w^T \vec x+b$$

其中$\vec w=(w_1;w_2;...;w_d)$。$\vec w$和b学得后即可确定模型。

## 3.2 线性回归

_线性回归_ 试图学得一个线性模型，尽可能准确预测实值输出标记。  
对于离散属性：  
若属性值存在 _序_ 的关系，通过连续化将其转化为连续值；  
若不存在序关系，则通常转化为k维向量。  
确定w和b，试图使均方误差最小化：  

$$(w^*,b^*)=arg\ min{\sum^{m}_{i=1}{(f(x_i)-y_i)^2}}$$

_最小二乘法_ 试图找到所有样本到直线的欧式距离之和最小的一条直线。  

## 3.3 对数几率回归

对于分类任务，找一个单调可微函数将分类任务的真实标记y与线性回归模型的预测值联系起来。  
对于二分类任务，将实值z转换成0/1值。 _单位跃迁函数_ ：

$$y=\begin{cases}
0,\ z<0; \\
0.5,\ z=0;\\
1,\ z>0,
\end{cases}$$

单位跃迁函数不连续，使用对数几率函数替代：

$$y={1 \over {1-e^{-z}}}$$

对数几率回归，是一种分类方法，还可以近似概率预测。  

## 3.4 线性判别分析

线性判别分析（Linear Discriminant Analysis，LDA）一种经典的线性学习方法。  
思想：给定训练样例集，设法将样例投影到一条直线上，使同类样例的投影点尽可能接近、异类样例的投影尽可能远离；对新样本进行分类时，将其投影到同样这条直线上，再根据投影点的位置来确定新样本的类别。  
LDA也被视为一种经典的监督降维技术。  

## 3.5 多分类技术

先对问题进行拆分，对每个拆分出来的任务训练一个分类器；测试时，对分类器的预测结果进行集成获得最终的多分类结果。  
经典的三种拆分策略： _一对一_ （OvO）、 _一对其余_ （OvR）、 _多对多_ （MvM）。  

* OvO将N个类别两两配对，从而产生N(N-1)/2个二分类任务。
* OvR每次将一个类的样例作为正例、所有其他类作为反例来训练N个分类器。
* MvM每次将若干个类作为正类，若干个其他类作为反类。 _纠错输出码_

## 3.6 类别不平衡问题

分类任务中不同类别的训练样例数目差别很大的情况。  
令$m^+$表示正例数目，$m_-$表示反例数目，只要分类器的预测几率高于观测几率就应当判定为正例：  

$${y \over {1-y}}>{{m^+} \over {m^-}}$$

_再缩放_：

$${y' \over {1-y'}}={y \over {1-y}} \times {m^- \over m^+}$$

使得 _训练集是真实样本的无偏采样_ 有三类技术：  

* _欠采样_ ：丢弃部分反例
* _过采样_ ：增加部分正例
* _阈值移动_ ：使用原始训练集，进行预测时，嵌入再缩放公式

# 第4章 决策树

## 4.1 基本流程


