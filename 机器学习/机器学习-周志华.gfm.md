<!-- GFM-TOC -->
* [第1章 绪论](#第1章-绪论)
    * [1.1 引言](#11-引言)
    * [1.2 基于术语](#12-基于术语)
    * [1.3 假设空间](#13-假设空间)
    * [1.4 归纳偏好](#14-归纳偏好)
    * [1.5 发展历程](#15-发展历程)
    * [1.6 应用现状](#16-应用现状)
* [第2章 模型评估与选择](#第2章-模型评估与选择)
    * [2.1 经验误差与过拟合](#21-经验误差与过拟合)
    * [2.2 评估方法](#22-评估方法)
        * [2.2.1 留出法](#221-留出法)
        * [2.2.2 交叉验证法](#222-交叉验证法)
        * [2.2.3 自助法](#223-自助法)
        * [2.2.4 调参与最终模型](#224-调参与最终模型)
    * [2.3 性能度量](#23-性能度量)
        * [2.3.1 错误率与精度](#231-错误率与精度)
        * [2.3.2 查准率、查全率与F1](#232-查准率查全率与f1)
        * [2.3.3 ROC与AUC](#233-roc与auc)
        * [2.3.4 代价敏感错误率与代价曲线](#234-代价敏感错误率与代价曲线)
    * [2.4 比较检验](#24-比较检验)
        * [2.4.1 假设检验](#241-假设检验)
        * [2.4.2 交叉验证t检验](#242-交叉验证t检验)
        * [2.4.3 McNemar检验](#243-mcnemar检验)
        * [2.4.4 Friedman检验与Nemenyi后续检验](#244-friedman检验与nemenyi后续检验)
    * [2.5 偏差与方差](#25-偏差与方差)
* [第3章 线性模型](#第3章-线性模型)
    * [3.1 基本形式](#31-基本形式)
    * [3.2 线性回归](#32-线性回归)
    * [3.3 对数几率回归](#33-对数几率回归)
    * [3.4 线性判别分析](#34-线性判别分析)
    * [3.5 多分类技术](#35-多分类技术)
    * [3.6 类别不平衡问题](#36-类别不平衡问题)
* [第4章 决策树](#第4章-决策树)
    * [4.1 基本流程](#41-基本流程)
    * [4.2 划分选择](#42-划分选择)
        * [4.2.1 信息增益](#421-信息增益)
        * [4.2.2 增益率](#422-增益率)
        * [4.2.3 基尼指数](#423-基尼指数)
    * [4.3 剪枝处理](#43-剪枝处理)
        * [4.3.1 预剪枝](#431-预剪枝)
        * [4.3.2 后剪枝](#432-后剪枝)
    * [4.4 连续与缺失值](#44-连续与缺失值)
        * [4.4.1 连续值处理](#441-连续值处理)
        * [4.4.2 缺失值处理](#442-缺失值处理)
    * [4.5 多变量决策树](#45-多变量决策树)
* [第5章 神经网络](#第5章-神经网络)
    * [5.1 神经元模型](#51-神经元模型)
    * [5.2 感知机与多层网络](#52-感知机与多层网络)
    * [5.3 误差逆传播算法](#53-误差逆传播算法)
    * [5.4 全局最小与局部最小](#54-全局最小与局部最小)
    * [5.5 其他常见神经网络](#55-其他常见神经网络)
        * [5.5.1 RBF网络](#551-rbf网络)
        * [5.5.2 ART网络](#552-art网络)
        * [5.5.3 SOM网络](#553-som网络)
        * [5.5.4 级联相关网络](#554-级联相关网络)
        * [5.5.5 Elman网络](#555-elman网络)
        * [5.5.6 Boltzmann机](#556-boltzmann机)
    * [5.6 深度学习](#56-深度学习)
* [第6章 支持向量机](#第6章-支持向量机)
    * [6.1 间隔与支持向量](#61-间隔与支持向量)
    * [6.2 对偶问题](#62-对偶问题)
    * [6.3 核函数](#63-核函数)
    * [6.4 软间隔与正则化](#64-软间隔与正则化)
    * [6.5 支持向量回归](#65-支持向量回归)
    * [6.6 核方法](#66-核方法)
* [第7章 贝叶斯分类器](#第7章-贝叶斯分类器)
    * [7.1 贝叶斯决策论](#71-贝叶斯决策论)
    * [7.2 极大似然估计](#72-极大似然估计)
    * [7.3 朴素贝叶斯分类器](#73-朴素贝叶斯分类器)
    * [7.4 半朴素贝叶斯分类器](#74-半朴素贝叶斯分类器)
    * [7.5 贝叶斯网](#75-贝叶斯网)
        * [7.5.1 结构](#751-结构)
        * [7.5.2 学习](#752-学习)
        * [7.5.3 推断](#753-推断)
    * [7.6 EM算法](#76-em算法)
* [第8章 集成学习](#第8章-集成学习)
    * [8.1 个体与集成](#81-个体与集成)
    * [8.2 Boosting](#82-boosting)
    * [8.3 Bagging与随机森林](#83-bagging与随机森林)
        * [8.3.1 Bagging](#831-bagging)
        * [8.3.2 随机森林](#832-随机森林)
    * [8.4 结合策略](#84-结合策略)
        * [8.4.1 平均法](#841-平均法)
        * [8.4.2 投票法](#842-投票法)
        * [8.4.3 学习法](#843-学习法)
    * [8.5 多样性](#85-多样性)
        * [8.5.1 误差-分歧分解](#851-误差-分歧分解)
        * [8.5.2 多样性度量](#852-多样性度量)
        * [8.5.3 多样性增强](#853-多样性增强)
* [第9章 聚类](#第9章-聚类)
    * [9.1 聚类任务](#91-聚类任务)
    * [9.2 性能度量](#92-性能度量)
    * [9.3 距离计算](#93-距离计算)
    * [9.4 原型聚类](#94-原型聚类)
        * [9.4.1 k均值算法](#941-k均值算法)
        * [9.4.2 学习向量量化](#942-学习向量量化)
        * [9.4.3 高斯混合聚类](#943-高斯混合聚类)
    * [9.5 密度聚类](#95-密度聚类)
    * [9.6 层次聚类](#96-层次聚类)
* [第10章 降维与度量学习](#第10章-降维与度量学习)
    * [10.1 k近邻学习](#101-k近邻学习)
    * [10.2 低维嵌入](#102-低维嵌入)
    * [10.3 主成分分析](#103-主成分分析)
    * [10.4 核化线性降维](#104-核化线性降维)
    * [10.5 流形学习](#105-流形学习)
        * [10.5.1 等度量映射](#1051-等度量映射)
        * [10.5.2 局部线性嵌入](#1052-局部线性嵌入)
    * [10.6 度量学习](#106-度量学习)
* [第11章 特征选择与稀疏学习](#第11章-特征选择与稀疏学习)
    * [11.1 子集搜索与评价](#111-子集搜索与评价)
    * [11.2 过滤式选择](#112-过滤式选择)
    * [11.3 包裹式选择](#113-包裹式选择)
    * [11.4 嵌入式选择与<img src="https://latex.codecogs.com/gif.latex?L_1"/>正则化](#114-嵌入式选择与<img-src="httpslatexcodecogscomgiflatex?l_1">正则化)
    * [11.5 稀疏表示与字典学习](#115-稀疏表示与字典学习)
    * [11.6 压缩感知](#116-压缩感知)
* [第12章 计算学习理论](#第12章-计算学习理论)
    * [12.1 基础知识](#121-基础知识)
    * [12.2 PAC学习](#122-pac学习)
    * [12.3 有限假设空间](#123-有限假设空间)
        * [12.3.1 可分情形](#1231-可分情形)
        * [12.3.2 不可分情形](#1232-不可分情形)
    * [12.4 VC维](#124-vc维)
    * [12.5 Rademacher复杂度](#125-rademacher复杂度)
    * [12.6 稳定性](#126-稳定性)
* [第13章 半监督学习](#第13章-半监督学习)
    * [13.1 未标记样本](#131-未标记样本)
    * [13.2 生成式方法](#132-生成式方法)
    * [13.3 半监督SVM](#133-半监督svm)
    * [13.4 图半监督学习](#134-图半监督学习)
    * [13.5 基于分歧的方法](#135-基于分歧的方法)
    * [13.6 半监督聚类](#136-半监督聚类)
* [第14章 概率图模型](#第14章-概率图模型)
    * [14.1 隐马尔可夫模型](#141-隐马尔可夫模型)
    * [14.2 马尔可夫随机场](#142-马尔可夫随机场)
    * [14.3 条件随机场](#143-条件随机场)
    * [14.4 学习与推断](#144-学习与推断)
        * [14.4.1 变量消去](#1441-变量消去)
        * [14.4.2 信念传播](#1442-信念传播)
    * [14.5 近似推断](#145-近似推断)
        * [14.5.1 MCMC采样](#1451-mcmc采样)
        * [14.5.2 变分推断](#1452-变分推断)
    * [14.6 话题模型](#146-话题模型)
* [第15章 规则学习](#第15章-规则学习)
    * [15.1 基本概念](#151-基本概念)
    * [15.2 序贯覆盖](#152-序贯覆盖)
    * [15.3 剪枝优化](#153-剪枝优化)
    * [15.4 一阶规则学习](#154-一阶规则学习)
    * [15.5 归纳逻辑程序设计](#155-归纳逻辑程序设计)
        * [15.5.1 最小一般泛化](#1551-最小一般泛化)
        * [15.5.2 逆归结](#1552-逆归结)
* [第16章 强化学习](#第16章-强化学习)
    * [16.1 任务与奖赏](#161-任务与奖赏)
    * [16.2 K-摇臂赌博机](#162-k-摇臂赌博机)
        * [16.2.1 探索与利用](#1621-探索与利用)
        * [16.2.2 <img src="https://latex.codecogs.com/gif.latex?\epsilon"/>-贪心](#1622-<img-src="httpslatexcodecogscomgiflatex?\epsilon">-贪心)
        * [16.2.3 Softmax](#1623-softmax)
    * [16.3 有模型学习](#163-有模型学习)
        * [16.3.1 策略评估](#1631-策略评估)
        * [16.3.2 策略改进](#1632-策略改进)
        * [16.3.3 策略迭代与值迭代](#1633-策略迭代与值迭代)
    * [16.4 免模型学习](#164-免模型学习)
        * [16.4.1 蒙特卡罗强化学习](#1641-蒙特卡罗强化学习)
        * [16.4.2 时序差分学习](#1642-时序差分学习)
    * [16.5 值函数近似](#165-值函数近似)
    * [16.6 模仿学习](#166-模仿学习)
        * [16.6.1 直接模仿学习](#1661-直接模仿学习)
        * [16.6.2 逆强化学习](#1662-逆强化学习)
<!-- GFM-TOC -->


# 第1章 绪论
## 1.1 引言
## 1.2 基于术语
_数据集_  
_示例或样本_  
_属性或特性_  
_属性值_  
_属性空间、样本空间或输入空间_  
_特征向量_：空间中每个点对应一个坐标向量  
<img src="https://latex.codecogs.com/gif.latex?D=\{x_1,x_2,...,x_m\}"/>表示包含m个示例的数据集。  
每个示例有d个属性描述，<img src="https://latex.codecogs.com/gif.latex?\vecx_i=(x_{i1};x_{i2};...;x_{id})"/>。  
预测离散值 分类  
预测连续值 回归  
## 1.3 假设空间
归纳（induction），“泛化”（generalization）  
演绎（deduction），“特化”（specialization）  
将学习过程看做一个在所有假设组成的空间中进行搜索的过程，搜索目标是找到与训练集匹配的假设。  
## 1.4 归纳偏好
* __归纳偏好__：机器学习算法在学习过程中对某种类型假设的偏好。  
任何有效的机器学习算法必有其归纳偏好。  
* 引导算法确立偏好的一般性原则：__奥卡姆剃刀__ ，若有多个假设与观察一致，则选最简单的那个。  
* __没有免费午餐__ 定理（NFL定理）：所有问题出现机会相同、或所有问题同等重要的前提下，所有学习算法期望值相同。  
谈论算法的优劣，必须针对具体的学习问题。  
## 1.5 发展历程
## 1.6 应用现状

---
# 第2章 模型评估与选择
## 2.1 经验误差与过拟合
* 训练集上的误差 _训练误差_ 或 _经验误差_。  
* 新样本上的误差 _泛化误差_。  
* 过拟合是ML的关键障碍。
* ML面临NP难。  
## 2.2 评估方法
从数据集中分出训练集和测试集。  
### 2.2.1 留出法
直接将数据基划分为两个互斥的集合。  
尽量保持数据分布的一致性。  
___一般采用若干次随机划分、重复进行实验评估后取平均值作留出法的评估结果___。  
### 2.2.2 交叉验证法
* 数据集划分成k个大小相似的互斥子集。  
* 每个子集尽可能保持数据分布的一致性。  
* 每次用k-1个子集作为训练集、余下的那个子集作为测试集。  
* 最终返回k个测试结果的均值。  
### 2.2.3 自助法
* 以自助采样法为基础。  
* 对数据集D采样生成数据集D'：
    * 每次从D中挑选一个样本，将其拷贝放入D'中，然后再将该样本放回初始数据集D中。  
    * 该过程重复m次，就获得了包含m个样本的D'。
* D中约有36.8%的样本未出现在采样数据集D'中。
* 用D'做测试集。
* 改变了数据集的分布，产生了估计偏差。  
### 2.2.4 调参与最终模型
## 2.3 性能度量
### 2.3.1 错误率与精度
### 2.3.2 查准率、查全率与F1
* 分类结果混淆矩阵

| 真实情况\预测结果 | 正例 | 反例 |
| - | - | - |
| 正例 | TP（真正例） | FN（假反例） |
| 反例 | FP（假正例） | TN（真反例） |
* 查准率P，检索出的信息有多少是用户关心的：  
<div align="center"><img src="https://latex.codecogs.com/gif.latex?P={TP\over{TP+FP}}"/></div> <br>
* 查全率R，用户感兴趣的信息有多少被检索出来了：  
<div align="center"><img src="https://latex.codecogs.com/gif.latex?R={TP\over{TP+FN}}"/></div> <br>
* 查准率-查全率曲线 P-R图
学习器A的P-R曲线完全包住了学习器B的曲线，可以认为A的性能高于B。  
平衡点：查准率=查全率时的取值。  
* F1度量：
<div align="center"><img src="https://latex.codecogs.com/gif.latex?F1={{2\timesP\timesR}\over{P+R}}={{2\timesTP}\over{样本总数+TP-TN}}"/></div> <br>
F1度量的一般形式<img src="https://latex.codecogs.com/gif.latex?F_\beta"/>，定义：
<div align="center"><img src="https://latex.codecogs.com/gif.latex?F_\beta={{(1+\beta^2)\timesP\timesR}\over{(\beta^2\timesP)+R}}"/></div> <br>
其中<img src="https://latex.codecogs.com/gif.latex?\beta>0"/>。<img src="https://latex.codecogs.com/gif.latex?\beta=1"/>时退化为标准F1；<img src="https://latex.codecogs.com/gif.latex?\beta>1"/>时，查全率有更大影响；<img src="https://latex.codecogs.com/gif.latex?\beta<1"/>时，查准率有更大影响。  
### 2.3.3 ROC与AUC
* ROC受试者工作特性
ROC曲线使用真正例率TPR-假正例率FPR：  
<div align="center"><img src="https://latex.codecogs.com/gif.latex?TPR={{TP}\over{TP+FN}}"/></div> <br>
<div align="center"><img src="https://latex.codecogs.com/gif.latex?FPR={{FP}\over{TN+FP}}"/></div> <br>
比较学习器的性能，比较ROC曲线下的面积，即AUC（Area Under ROC Curve）。  
### 2.3.4 代价敏感错误率与代价曲线
非均等代价：权衡不同类型错误所造成的不同损失。  
## 2.4 比较检验
### 2.4.1 假设检验

* 二项检验
* t检验

### 2.4.2 交叉验证t检验

### 2.4.3 McNemar检验

检验两学习器的分类结果的差别。

### 2.4.4 Friedman检验与Nemenyi后续检验

在一组数据集上比较多个算法。  

* 基于算法排序的Friedman检验
    * 使用留出法或交叉验证法得到每个算法在每个数据集上的测试结果；
    * 根据性能进行排序；
    * 测试性能相同则平分序值；
    * 使用Friedman检验判断算法性能是否相同。
    
若算法性能显著不同，使用后续检验来进一步区分。常用Nemenyi后续检验。  
Nemenyi检验计算出平均序值差别的临界值域  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?CD={q_\alpha{\sqrt{{k(k+1)}\over{6N}}}}"/></div> <br>

若两算法的平均序值之差超出临界值域CD，则以相应的置信度拒绝“两个算法性能相同”这一假设。  

## 2.5 偏差与方差

_偏差-方差分解_ 是解释学习算法泛化性能的一种重要工具。  
泛化误差可以分解成偏差、方差和噪声之和。  
_偏差_ 度量了学习算法本身的拟合能力；  
_方差_ 刻画了数据扰动所造成的影响；  
_噪声_ 刻画了学习问题本身的难度。  

---

# 第3章 线性模型

## 3.1 基本形式

给定由d个属性描述的<img src="https://latex.codecogs.com/gif.latex?\vecx=(x_1;x_2;...;x_d)"/>  
线性模型视图学得一个通过属性的线性组合进行预测的函数：

<div align="center"><img src="https://latex.codecogs.com/gif.latex?f(\vecx)=w_1x_1+w_2x_2+...+w_dx_d+b"/></div> <br>

向量形式：

<div align="center"><img src="https://latex.codecogs.com/gif.latex?f(\vecx)=\vecw^T\vecx+b"/></div> <br>

其中<img src="https://latex.codecogs.com/gif.latex?\vecw=(w_1;w_2;...;w_d)"/>。<img src="https://latex.codecogs.com/gif.latex?\vecw"/>和b学得后即可确定模型。

## 3.2 线性回归

_线性回归_ 试图学得一个线性模型，尽可能准确预测实值输出标记。  
对于离散属性：  
若属性值存在 _序_ 的关系，通过连续化将其转化为连续值；  
若不存在序关系，则通常转化为k维向量。  
确定w和b，试图使均方误差最小化：  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?(w^*,b^*)=arg\min{\sum^{m}_{i=1}{(f(x_i)-y_i)^2}}"/></div> <br>

_最小二乘法_ 试图找到所有样本到直线的欧式距离之和最小的一条直线。  

## 3.3 对数几率回归

对于分类任务，找一个单调可微函数将分类任务的真实标记y与线性回归模型的预测值联系起来。  
对于二分类任务，将实值z转换成0/1值。 _单位跃迁函数_ ：

$$y=\begin{cases}
0,\ z<0; \\
0.5,\ z=0;\\
1,\ z>0,
\end{cases}$$

单位跃迁函数不连续，使用对数几率函数替代：

<div align="center"><img src="https://latex.codecogs.com/gif.latex?y={1\over{1-e^{-z}}}"/></div> <br>

对数几率回归，是一种分类方法，还可以近似概率预测。  

## 3.4 线性判别分析

线性判别分析（Linear Discriminant Analysis，LDA）一种经典的线性学习方法。  
思想：给定训练样例集，设法将样例投影到一条直线上，使同类样例的投影点尽可能接近、异类样例的投影尽可能远离；对新样本进行分类时，将其投影到同样这条直线上，再根据投影点的位置来确定新样本的类别。  
LDA也被视为一种经典的监督降维技术。  

## 3.5 多分类技术

先对问题进行拆分，对每个拆分出来的任务训练一个分类器；测试时，对分类器的预测结果进行集成获得最终的多分类结果。  
经典的三种拆分策略： _一对一_ （OvO）、 _一对其余_ （OvR）、 _多对多_ （MvM）。  

* OvO将N个类别两两配对，从而产生N(N-1)/2个二分类任务。
* OvR每次将一个类的样例作为正例、所有其他类作为反例来训练N个分类器。
* MvM每次将若干个类作为正类，若干个其他类作为反类。 _纠错输出码_

## 3.6 类别不平衡问题

分类任务中不同类别的训练样例数目差别很大的情况。  
令<img src="https://latex.codecogs.com/gif.latex?m^+"/>表示正例数目，<img src="https://latex.codecogs.com/gif.latex?m_-"/>表示反例数目，只要分类器的预测几率高于观测几率就应当判定为正例：  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?{y\over{1-y}}>{{m^+}\over{m^-}}"/></div> <br>

_再缩放_：

<div align="center"><img src="https://latex.codecogs.com/gif.latex?{y'\over{1-y'}}={y\over{1-y}}\times{m^-\overm^+}"/></div> <br>

使得 _训练集是真实样本的无偏采样_ 有三类技术：  

* _欠采样_ ：丢弃部分反例
* _过采样_ ：增加部分正例
* _阈值移动_ ：使用原始训练集，进行预测时，嵌入再缩放公式

---

# 第4章 决策树

## 4.1 基本流程

一颗决策树包含一个根结点、若干个内部结点和若干个叶结点；  
叶结点对应决策结果，其他结点对应一个属性测试；  
每个结点包含的样本集合根据属性测试结果被划分到子结点中；  
根结点包含样本全集。  
决策树的生成是递归过程。三种情况导致递归返回：  

* 当前结点包含的样本属于同一类别
* 当前属性集为空，或所有样本的所有属性取值相同
* 当前结点包含的样本为空

## 4.2 划分选择

希望结点的 _纯度_ 越来越高。

### 4.2.1 信息增益

当前样本集合D中第k类样本所占的比例为<img src="https://latex.codecogs.com/gif.latex?p_k"/>（k=1,2,...,|y|），则D的信息熵定义为：  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?Ent(D)=-\sum^{|y|}_{k=1}{p_k\log_2p_k}"/></div> <br>

Ent(D)的值越小，则D的纯度越高。  
第v个分支结点包含了D中所有在属性a上取值为<img src="https://latex.codecogs.com/gif.latex?a^v"/>的样本，记为<img src="https://latex.codecogs.com/gif.latex?D^v"/>。信息增益：  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?Gain(D,a)=Ent(D)-{\sum^V_{v=1}{{|D^v|}\over{|D|}}Ent(D^v)}"/></div> <br>

一般而言，信息增益越大，使用属性a进行划分所得的纯度提升越大。  

### 4.2.2 增益率

信息增益准则对可取值数目较多的属性有所偏好。  
不直接使用信息增益，而是 _增益率_ 来选择最优划分属性。  
增益率定义：  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?Gain\_ratio(D,a)={Gain(D,a)\overIV(a)}"/></div> <br>

其中IV(a)成为属性a的固有值。属性a的可能取值数目越多，IV(a)的值通常就越大。  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?IV(a)=-{\sum^V_{v=1}{{|D^v|}\over{|D|}}\log_2{|D^v|\over|D|}}"/></div> <br>

增益率准则对可取值数目较小的属性有所偏好。

### 4.2.3 基尼指数

数据集D的纯度可以用 _基尼值_ 来度量：  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?Gini(D)={\sum^{|y|}_{k=1}\sum_{k'\neqk}p_kp_{k'}}=1-{\sum^{|y|}_{k=1}p^2_k}"/></div> <br>

Gini(D)越小，数据集D的纯度越高。  
属性a的基尼指数定义：  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?Gini\_index(D,a)={\sum^V_{v=1}{|D^v|\over|D|}Gini(D^v)}"/></div> <br>

## 4.3 剪枝处理

决策树学习算法对付过拟合的主要手段。  
基本策略 _预剪枝_ 和 _后剪枝_。  
_预剪枝_：决策树生成过程中，对每个结点在划分前进行估计，若当前结点的划分不能带来决策树泛化能力的提升，则停止划分当前结点，并标记为叶结点。  
_后剪枝_：自底向上对非叶结点进行考察，若当前结点对应的子树被替换成叶结点能带来泛化能力的提升，则进行替换。  

### 4.3.1 预剪枝

基于信息增益准则，验证集精度。  

### 4.3.2 后剪枝

## 4.4 连续与缺失值

### 4.4.1 连续值处理

最简单的策略是采用 _二分法_ 处理连续属性。  
基于划分点t将D分为子集<img src="https://latex.codecogs.com/gif.latex?D_t^-"/>和<img src="https://latex.codecogs.com/gif.latex?D_t^+"/>。  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?Gain(D,a)=\max\limits_{t\in{T_a}}Gain(D,a,t)"/></div> <br>

### 4.4.2 缺失值处理

* _如何在属性值缺失的情况下，进行划分属性选择_
给定训练集D和属性a，令<img src="https://latex.codecogs.com/gif.latex?\tilde{D}"/>表示D中属性a上没有缺失值的样本子集。  
仅使用<img src="https://latex.codecogs.com/gif.latex?\tilde{D}"/>来判断属性优劣。  
* _给定划分属性，若样本在该属性上的值缺失，如何对样本进行划分_
若样本x在划分属性a上的取值未知，则将x同时划入所有的子结点，且样本权值与属性值<img src="https://latex.codecogs.com/gif.latex?a^v"/>对应的子结点中调整为<img src="https://latex.codecogs.com/gif.latex?\tilde{r}_v\cdot{w_x}"/>。即 ___让同一个样本以不同的概率划分到不同的子结点中去___。

## 4.5 多变量决策树

决策树形成的分类边界有一个明显的特点： _轴平行_，即它的分类边界由若干个与坐标轴平行的分段组成。  
当划分段数过多时，决策树会相当复杂。  
采用斜的划分边界能大为简化模型。  
__多变量决策树__ 就是实现这样的 _斜划分_ 甚至更复杂划分的决策树。  

---

# 第5章 神经网络

## 5.1 神经元模型

_M-P神经元模型_：神经元接收到来自n个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接进行传递，神经元接收到的总输入值将于神经元的阈值进行比较，通过 _激活函数_ 处理以产生神经元的输出。  
理想的激励函数是阶跃函数，实际常用Sigmoid函数。  

## 5.2 感知机与多层网络

感知机有两层神经元组成。能够容易地实现与、或、非运算。  
感知机只有输出层神经元进行激活函数处理，学习能力有限，只能解决线性可分问题，即 _存在一个线性超平面能够将两类模式分开_，则感知机的学习过程一定会收敛。  
解决非线性可分问题，需要使用多层功能神经元。 _多层前馈神经网络_。  
神经网络学习到的东西蕴含在 ___连接权___ 与 ___阈值___ 中。  

## 5.3 误差逆传播算法

__误差逆传播__ 算法（error BackPropagation，BP）。  
BP算法不仅可以用于多层前馈神经网络，还可用于其他类型的神经网络。  
_BP网络_ 一般指用BP算法训练的多层前馈神经网络。  
给定训练集<img src="https://latex.codecogs.com/gif.latex?D=\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\},x_i\in\R^d,y_i\in\R^l"/>，即输入示例由d个属性描述，输出l维实值向量。  
BP算法基于梯度下降策略（gradient descent），以目标的负梯度方向对参数进行调整。  
只需一个包含足够多的神经元的隐层，多层前馈神经网络就能够以任意精度逼近任意复杂度的连续函数。  

## 5.4 全局最小与局部最小

_局部极小_ 和 _全局最小_  
基于梯度的搜索是使用最为广泛的参数寻优方法。梯度下降法是沿着负梯度方向搜索最优解。  
使用以下策略跳出局部最小：  

* 以多组不同参数数值初始化多个神经网络，取误差最小的解作为最终参数。
* _模拟退火_ 技术
* 随机梯度下降
* 遗传算法

## 5.5 其他常见神经网络

### 5.5.1 RBF网络
RBF（Radial Basis Function，径向基函数）网络。一种单隐层前馈神经网络。  
使用径向基函数作为隐层神经元激活函数，输出层是对隐层神经元输出的线性组合。  
假定输入d维向量<img src="https://latex.codecogs.com/gif.latex?\vec{x}"/>，输出为实值，RBF网络表示为  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?\varphi(\vec{x})=\sum^{q}_{i=1}{w_i\rho(\vec{x},c_i)}"/></div> <br>

其中<img src="https://latex.codecogs.com/gif.latex?q"/>为隐层神经元个数，<img src="https://latex.codecogs.com/gif.latex?c_i"/>和<img src="https://latex.codecogs.com/gif.latex?w_i"/>分别为第<img src="https://latex.codecogs.com/gif.latex?i"/>个隐层神经元对应的中心和权重，<img src="https://latex.codecogs.com/gif.latex?\rho(\vec{x},c_i)"/>是径向基函数。  

### 5.5.2 ART网络

竞争性学习是神经网络中一种无监督学习策略。  
该策略中，网络的输出神经元相互竞争，每时刻仅有一个神经元被激活，其他神经元的状态被抑制。_胜者通吃_ 原则。  
ART（Adaptive Resonance Theory，自适应谐振理论）网络是竞争学习的重要代表。  
该网络由比较层、识别层、识别阈值和重置模块构成。  

### 5.5.3 SOM网络

SOM（Self-Organizing Map，自组织映射）网络，一种竞争学习型的无监督神经网络。  

### 5.5.4 级联相关网络

结构自适应网络将网络结构也当做学习目标之一，并希望能在训练过程中找到最符合数据特点的网络结构。  
级联相关网络是结构自适应网络的重要代表。  

### 5.5.5 Elman网络

_递归神经网络_ 允许网络中出现环状结构，从而让一些神经元的输出反馈回来作为输入信号。  
Elman网络是最常用的递归神经网络之一。  

### 5.5.6 Boltzmann机

神经网络中有一类模型是为了网络状态定义一个 _能量_，能量最小化时，网络达到理想状态，网络的训练就是在最小化这个能量函数。  
Boltzmann机就是一种 _基于能量的模型_。  

## 5.6 深度学习

典型的深度学习模型就是很深的神经网络。  
增加隐层的数目。  

* _无监督逐层训练_
多隐层网络训练的有效手段。_预训练_ + _微调_。  
* _权共享_
节省训练开销的策略。让一组神经元使用相同的连接权。  

无论是DBN还是CNN，通过多层处理，逐渐将初始的低层特征表示转换为高层特征表示，用简单模型即完成复杂的分类等学习任务。  
可将深度学习理解为 _特征学习_ 或 _表示学习_。  

---

# 第6章 支持向量机

## 6.1 间隔与支持向量

选取的划分超平面产生的分类结果是最鲁棒的，对于未见示例的泛化能力最强。  
划分超平面通过如下的线性方程来描述：  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?\vec{w}^T\vec{x}+b=0"/></div> <br>

<img src="https://latex.codecogs.com/gif.latex?\vec{w}=(w_1;w_2;...;w_d)"/>为法向量；b为位移项。  
两个异类支持向量到超平面的距离之和称为 _间隔_。  

## 6.2 对偶问题

支持向量机的一个重要性质：训练完成后，大部分样本都不需要保留，最终样本仅与支持向量有关。  

## 6.3 核函数

原始样本空间也许并不存在一个正确划分两类样本的超平面。  
如果原始样本空间是有限维，那么一定存在一个高维特征空间使得样本可分。  
令<img src="https://latex.codecogs.com/gif.latex?\phi(\vec{x})"/>表示<img src="https://latex.codecogs.com/gif.latex?\vec{x}"/>映射后的特征向量，在特征空间划分超平面对应的模型可以表示为  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?f(\vec{x})=\vec{w}^T\phi(\vec{x})+b"/></div> <br>

求解后  

$$
\begin{aligned}
f(\vec{x})&=\vec{w}^T\phi(\vec{x})+b\\
&=\sum_{i=1}^{m}\alpha_iy_i\phi(\vec{x}_i)^T\phi(\vec{x})+b\\
&=\sum_{i=1}^{m}\alpha_iy_i\kappa(\vec{x},\vec{x}_i)+b
\end{aligned}
$$

函数<img src="https://latex.codecogs.com/gif.latex?\kappa(.,.)"/>就是 _核函数_。
__定理（核函数）__ 令<img src="https://latex.codecogs.com/gif.latex?\chi"/>为输入空间，<img src="https://latex.codecogs.com/gif.latex?\kappa(.,.)"/>是定义在<img src="https://latex.codecogs.com/gif.latex?\chi\times\chi"/>上对称函数，则<img src="https://latex.codecogs.com/gif.latex?\kappa"/>是核函数当且仅当对于任意数据<img src="https://latex.codecogs.com/gif.latex?D=\{\vec{x}_1,\vec{x}_2,...,\vec{x}_m\}"/>，_核矩阵_ K总是半正定的：  

$$
K=\begin{bmatrix}
   \kappa(\vec{x}_1,\vec{x}_1) & \dots & \kappa(\vec{x}_1,\vec{x}_j) & \dots & \kappa(\vec{x}_1,\vec{x}_m)\\
   \vdots & \ddots & \vdots & \ddots & \vdots\\
   \kappa(\vec{x}_i,\vec{x}_1) & \dots & \kappa(\vec{x}_i,\vec{x}_j) & \dots & \kappa(\vec{x}_i,\vec{x}_m)\\
   \vdots & \ddots & \vdots & \ddots & \vdots\\
   \kappa(\vec{x}_m,\vec{x}_1) & \dots & \kappa(\vec{x}_m,\vec{x}_j) & \dots & \kappa(\vec{x}_m,\vec{x}_m)
\end{bmatrix}
$$

## 6.4 软间隔与正则化

_软间隔_ 允许某些样本不满足约束  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?y_i(\vec{w}^T\vec{x}_i+b)\geq1"/></div> <br>

最大化间隔的同时，不满足约束的样本应尽可能少。  
三种替代损失函数：  

* hinge损失：<img src="https://latex.codecogs.com/gif.latex?l_{hinge}(z)=\max(0,1-z)"/>
* 指数损失：<img src="https://latex.codecogs.com/gif.latex?l_{exp}(z)=\exp(-z)"/>
* 对率损失：<img src="https://latex.codecogs.com/gif.latex?l_{\log}(z)=\log{(1+\exp{(-z)})}"/>

## 6.5 支持向量回归

_支持向量回归_ 假设我们能容忍<img src="https://latex.codecogs.com/gif.latex?f(\vec{x})"/>与真实输出<img src="https://latex.codecogs.com/gif.latex?y"/>之间最多有<img src="https://latex.codecogs.com/gif.latex?\epsilon"/>的偏差。相当于以<img src="https://latex.codecogs.com/gif.latex?f(\vec{x})"/>为中心，构建一个宽度为<img src="https://latex.codecogs.com/gif.latex?2\epsilon"/>的间隔带。  

## 6.6 核方法

__定理（表示定理）__ 令<img src="https://latex.codecogs.com/gif.latex?\Bbb{H}"/>为核函数<img src="https://latex.codecogs.com/gif.latex?\kappa"/>对于的再生核希尔伯特空间，<img src="https://latex.codecogs.com/gif.latex?\lVert{h}\rVert_{\Bbb{H}}"/>表示<img src="https://latex.codecogs.com/gif.latex?\Bbb{H}"/>空间中关于<img src="https://latex.codecogs.com/gif.latex?h"/>的范数，对于任意单调递增函数<img src="https://latex.codecogs.com/gif.latex?\Omega：[0,\infin]\mapsto\R"/>和任意非负损失函数<img src="https://latex.codecogs.com/gif.latex?l:\R^m\mapsto[0,\infin]"/>，优化问题  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?\min\limits_{h\in\Bbb{H}}F(h)=\Omega(\lVert{h}\rVert_{\Bbb{H}})+l(h(\vec{x}_1),h(\vec{x}_2),...,h(\vec{x}_m))"/></div> <br>

的解总可写为  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?h^*(\vec{x})=\sum_{i=1}^{m}\alpha_i\kappa(\vec{x},\vec{x}_i)"/></div> <br>

---

# 第7章 贝叶斯分类器

## 7.1 贝叶斯决策论

概率框架下实施决策的基本方法。对分类任务而言，在所有相关概率都已知的的理想情形下，贝叶斯决策论考虑如何基于这些概率和误判损失来选择最优的类别标记。  

## 7.2 极大似然估计

概率模型训练过程就是 _参数估计_。  
参数估计的解决方案之一：频率主义学派，参数虽然未知，但却是客观存在的固定值。极大似然估计。  

## 7.3 朴素贝叶斯分类器

_属性条件独立性假设_：对已知类别，假设所有属性相互独立。  
朴素贝叶斯分类器表达式：  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?h_{nb}(\vec{x})=\argmax\limits_{c\in{y}}P(c)\prod^{d}_{i=1}P(x_i|c)"/></div> <br>

## 7.4 半朴素贝叶斯分类器

基本思想：适当考虑一部分属性间的相互依赖信息，从而既不需要进行完全联合概率计算，又不至于彻底忽略了比较强的属性依赖关系。  
_独依赖估计_（One-Dependent Estimator，ODE）是半朴素贝叶斯分类器最常用的一种策略。  
_独依赖_ 就是假设每个属性在类别之外最多依赖于一个其他属性。  

## 7.5 贝叶斯网

_贝叶斯网_ 亦称 _信念网_ ，借助有向无环图刻画属性之间的依赖关系，使用条件概率表来描述属性的联合概率分布。  
一个贝叶斯网<img src="https://latex.codecogs.com/gif.latex?B"/>由结构<img src="https://latex.codecogs.com/gif.latex?G"/>和参数<img src="https://latex.codecogs.com/gif.latex?\Theta"/>两部分构成，<img src="https://latex.codecogs.com/gif.latex?B=\langle{G,\Theta}\rangle"/>。  
网络结构<img src="https://latex.codecogs.com/gif.latex?G"/>是一个有向无环图，每个结点对应一个属性；参数<img src="https://latex.codecogs.com/gif.latex?\Theta"/>定量描述这种依赖关系。  

### 7.5.1 结构

给定父结点集，贝叶斯网假设每个属性与它的非后裔属性独立，于是<img src="https://latex.codecogs.com/gif.latex?B=\langle{G,\Theta}\rangle"/>将属性<img src="https://latex.codecogs.com/gif.latex?x_1,x_2,...,x_d"/>的联合概率分布定义为  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?P_B(x_1,x_2,...,x_d)=\prod^{d}_{i=1}P_B(x_i|\pi_i)=\prod^{d}_{i=1}\theta_{x_i|\pi_i}"/></div> <br>

### 7.5.2 学习

贝叶斯网学习的首要任务就是根据训练数据集来找出结构最恰当的贝叶斯网。  
_评分搜索_ 是求解这一问题的常用办法。  

### 7.5.3 推断

贝叶斯网的近似推断使用吉布斯采样来完成。  

## 7.6 EM算法

_隐变量_ ：未观测变量。  
EM算法是常用语的估计参数隐变量的利器，迭代式的方法，基本思想：若参数<img src="https://latex.codecogs.com/gif.latex?\Theta"/>已知，则可根据训练数据推断出最优隐变量<img src="https://latex.codecogs.com/gif.latex?\Zeta"/>的值（E步）；反之，若<img src="https://latex.codecogs.com/gif.latex?\Zeta"/>的值已知，则可方便对参数<img src="https://latex.codecogs.com/gif.latex?\Theta"/>做极大似然估计（M步）。  
EM算法使用两个步骤交替计算：第一步是期望步（E）步，利用当前估计的参数值来计算对数似然的期望值；第二步是最大化（M）步，寻找能使E步产生的似然期望最大化的参数值。然后，新得到的参数值重新被用于E步，直至收敛到局部最优解。  

---

# 第8章 集成学习

## 8.1 个体与集成

_集成学习_ 通过构建并结合多个学习器来完成学习任务。  
同质集成， _基学习器_  
异质集成， _组件学习器_  
要想获得好的集成，个体学习器应当 _好而不同_，个体学习器要有一定的准确性，并且要有多样性，即学习器之间存在差异。  

## 8.2 Boosting

Boosting是一族可将弱学习器提升学习器的算法。  
从偏差-方差分解的角度看，Boosting主要关注降低偏差，因此Boosting能基于泛化能力相当弱的学习器构建出很强的集成。  

## 8.3 Bagging与随机森林

给定一个训练数据集，一种可能的做法就是对训练样本进行采样，产生若干个不同子集，再从每个数据子集中训练出一个基学习器。  

### 8.3.1 Bagging

Bagging是并行式集成学习方法的代表。  
直接基于自主采样法。  
Bagging的基本流程：采样出T个含有m个训练样本的采样集，基于每个采样集训练出一个基学习器，再将这些基学习器进行结合。  
Bagging对分类任务使用简单投票法，对回归任务使用简单平均法。  

### 8.3.2 随机森林

随机森林是Bagging的一个扩展变体。以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入随机属性选择。  
在RF中，对基决策树的每个结点，先从结点中随机选择一个包含k个属性的子集，然后再从这个子集中选择一个最优属性用于划分。  

## 8.4 结合策略

三个方面的好处：  

1. 统计的原因
2. 计算的原因
3. 表示的原因

### 8.4.1 平均法

对数值型输出<img src="https://latex.codecogs.com/gif.latex?h_i(\vec{x})\in\R"/>，最常见的结合策略是使用平均法。  

* 简单平均法
* 加权平均法

一般而言，在个体学习器性能相差较大时，宜使用加权平均法，而在个体学习器性能相近时，宜使用简单平均法。  

### 8.4.2 投票法

对于分类任务来说，学习器<img src="https://latex.codecogs.com/gif.latex?h_i"/>将从类别标记集合中预测出一个标记，常见的结合策略是使用投票法。  

* 绝对多数投票法
即若某标记得票过半数，则预测为该标记；否则拒绝预测。  
* 相对多数投票法
即预测为得票数最多的标记，若同时有多个标记获得最高票，则从中随机选择一个。
* 加权投票法

### 8.4.3 学习法

通过另一个学习器来进行结合。 _Stacking_ 是学习法的典型代表。  
把个体学习器称为初级学习器，用于结合的学习器称为次级学习器。  

## 8.5 多样性

### 8.5.1 误差-分歧分解

_误差-分歧分解_：个体学习器准确性越高、多样性越大，则集成越好。  

###  8.5.2 多样性度量

典型做法是考虑个体分类器的两两相似/不相似性。  
常见的多样性度量：  

* 不合度量
* 相关系数
* Q-统计量
* <img src="https://latex.codecogs.com/gif.latex?\kappa"/>-统计量

### 8.5.3 多样性增强

* 数据样本扰动
* 输入属性扰动
* 输出表示扰动
* 输出表示扰动
* 算法参数扰动

---

# 第9章 聚类

## 9.1 聚类任务

假定样本集<img src="https://latex.codecogs.com/gif.latex?D=\{\vec{x}_1,\vec{x}_2,...,\vec{x}_m\}"/>包含<img src="https://latex.codecogs.com/gif.latex?m"/>个无标记样本，每个样本<img src="https://latex.codecogs.com/gif.latex?\vec{x}_i=(x_{i1};x_{i2};...;x_{in})"/>是一个n维特征向量，则聚类算法将样本集D划分为$k$个不相交的簇。  

## 9.2 性能度量

_有效性指标_  
_簇内相似性_ 高且 _簇间相似度_ 低。  

* 将聚类结果与某一参考模型进行比较，称为 _外部指标_
    - Jaccard系数
    - FM指数（Fowlkes and Mallows Index，FMI）
    - Rand指数
* 直接考察聚类结果，称为 _内部指标_
    - DB指数（Davies-Bouldin Index，简称DBI）
    - Dunn指数（Dunn Index，DI）

## 9.3 距离计算

对函数<img src="https://latex.codecogs.com/gif.latex?dist(.,.)"/>，距离度量，满足一些基本性质：  

* 非负性：<img src="https://latex.codecogs.com/gif.latex?dist(\vec{x}_i,\vec{x}_j)\geq0"/>
* 同一性：<img src="https://latex.codecogs.com/gif.latex?dist(\vec{x}_i,\vec{x}_j)=0"/>当且仅当<img src="https://latex.codecogs.com/gif.latex?\vec{x}_i=\vec{x}_j"/>
* 对称性
* 直递性

_闵可夫斯基距离_  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?dist_{mk}(\vec{x}_i,\vec{x}_j)=(\sum^{n}_{u=1}|x_{iu}-x_{ju}|^p)^{1\over{p}}"/></div> <br>

<img src="https://latex.codecogs.com/gif.latex?p=2"/>时，闵可夫斯基距离即欧氏距离  
<img src="https://latex.codecogs.com/gif.latex?p=1"/>时，闵可夫斯基距离即曼哈顿距离  
闵可夫斯基距离可用于有序属性。对于无序属性，可采用VDM（Value Difference Metric）。  
将闵可夫斯基距离与VDM结合即可处理混合属性。  

## 9.4 原型聚类

_基于原型的聚类_ 假设聚类结构通过一组原型刻画。  

### 9.4.1 k均值算法

给定样本集<img src="https://latex.codecogs.com/gif.latex?D=({\vec{x}_1,\vec{x}_2,...,\vec{x}_m})"/>，k均值算法针对所得簇划分<img src="https://latex.codecogs.com/gif.latex?c=\{C_1,C_2,...,C_k\}"/>最小化平方误差  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?E=\sum^{k}_{i=1}\sum_{\vec{x}\in{C_i}}\lVert{\vec{x}-\vec{\mu_i}}\rVert_2^2"/></div> <br>

其中<img src="https://latex.codecogs.com/gif.latex?\vec\mu_i={1\over{|C_i|}}\sum_{x\in{C_i}}\vec{x}"/>是簇<img src="https://latex.codecogs.com/gif.latex?C_i"/>的均值向量。  
k均值算法采用贪心策略，通过迭代优化来近似求解。  

### 9.4.2 学习向量量化

_学习向量量化_ 试图找到一组原型向量来刻画聚类结构，LVQ假设数据样本带有类别标记，学习过程利用这些样本的监督信息来辅助聚类。  

### 9.4.3 高斯混合聚类

采用概率模型来表达聚类原型。

## 9.5 密度聚类

此类算法假设聚类结构能够通过样本分布的紧密程度确定。密度聚类算法从样本密度的角度来考察样本之间的可连接性，并基于连接样本不断拓展聚类簇以获得最终的效果。  
DBSCAN是一种著名的密度聚类算法，基于一组邻域参数<img src="https://latex.codecogs.com/gif.latex?(\epsilon,MinPts)"/>来刻画样本分布的紧密程度。  
给定数据集<img src="https://latex.codecogs.com/gif.latex?D=\{\vec{x}_1,\vec{x}_2,...,\vec{x}_m\}"/>，定义一下几个概念：  

* <img src="https://latex.codecogs.com/gif.latex?\epsilon"/>邻域：对<img src="https://latex.codecogs.com/gif.latex?\vec{x}_j\in{D}"/>，其<img src="https://latex.codecogs.com/gif.latex?\epsilon"/>-邻域包含样本集D中与<img src="https://latex.codecogs.com/gif.latex?\vec{x}_j"/>的距离不大于<img src="https://latex.codecogs.com/gif.latex?\epsilon"/>的样本。
* 核心对象：若<img src="https://latex.codecogs.com/gif.latex?\vec{x}_j"/>的<img src="https://latex.codecogs.com/gif.latex?\epsilon"/>-邻域至少包含<img src="https://latex.codecogs.com/gif.latex?MinPts"/>个样本，则<img src="https://latex.codecogs.com/gif.latex?\vec{x}_j"/>是一个核心对象。
* 密度直达：若<img src="https://latex.codecogs.com/gif.latex?\vec{x}_j"/>位于<img src="https://latex.codecogs.com/gif.latex?\vec{x}_i"/>的<img src="https://latex.codecogs.com/gif.latex?\epsilon"/>-邻域中，且<img src="https://latex.codecogs.com/gif.latex?\vec{x}_i"/>是核心对象，则称<img src="https://latex.codecogs.com/gif.latex?\vec{x}_j"/>由<img src="https://latex.codecogs.com/gif.latex?\vec{x}_i"/>密度直达。
* 密度可达：对<img src="https://latex.codecogs.com/gif.latex?\vec{x}_i"/>与<img src="https://latex.codecogs.com/gif.latex?\vec{x}_j"/>，若存在样本序列<img src="https://latex.codecogs.com/gif.latex?\vec{p}_1,\vec{p}_2,...,\vec{p}_n"/>，其中<img src="https://latex.codecogs.com/gif.latex?\vec{p}_1=\vec{x}_i"/>，<img src="https://latex.codecogs.com/gif.latex?\vec{p}_n=\vec{x}_j"/>且<img src="https://latex.codecogs.com/gif.latex?\vec{p}_{i+1}"/>由<img src="https://latex.codecogs.com/gif.latex?\vec{p}_i"/>密度直达，则称<img src="https://latex.codecogs.com/gif.latex?\vec{x}_j"/>由<img src="https://latex.codecogs.com/gif.latex?\vec{x}_i"/>密度可达。
* 密度相连：对<img src="https://latex.codecogs.com/gif.latex?\vec{x}_i"/>与<img src="https://latex.codecogs.com/gif.latex?\vec{x}_j"/>，若存在<img src="https://latex.codecogs.com/gif.latex?\vec{x}_k"/>使得<img src="https://latex.codecogs.com/gif.latex?\vec{x}_i"/>与<img src="https://latex.codecogs.com/gif.latex?\vec{x}_j"/>均由<img src="https://latex.codecogs.com/gif.latex?\vec{x}_k"/>密度可达，则称<img src="https://latex.codecogs.com/gif.latex?\vec{x}_i"/>与<img src="https://latex.codecogs.com/gif.latex?\vec{x}_j"/>密度相连。

DBSCAN将簇定义为：由密度可达关系导出的最大的密度相连样本集合。  

## 9.6 层次聚类

试图在不同层次对数据集进行划分，从而形成树形的聚类结构。  
数据集的划分可采用 _自底向上_ 的聚合策略，也可采用 _自顶向下_ 的分拆策略。  

---

# 第10章 降维与度量学习

## 10.1 k近邻学习

k近邻（kNN）学习是一种常见的监督学习方法。  
工作机制：给定测试样本，基于某种距离度量找出训练集中与其最靠近的k个训练样本，然后基于这k个邻居的信息来进行预测。  
在分类任务中使用投票法，在回归任务中使用平均法。  
kNN是 _懒惰学习_ 的著名代表。在训练阶段仅仅是把样本保存起来，训练时间开销为零，待收到测试样本再进行处理。  

## 10.2 低维嵌入

高维情形下出现的数据样本稀疏、距离计算困难等问题，是所有机器学习面临的严重障碍，称为 _维数灾难_。
_降维_ 或 _维数约简_。  
若要求原始空间中样本之间的距离在低维空间中得以保持，得到 _多维缩放_。  

## 10.3 主成分分析

一种常用的降维方法。  
降维导致部分特征向量被舍弃，这是降维的必然结果，也是必要的  

* 增大采样密度
* 去噪

## 10.4 核化线性降维

非线性降维的一种常用方法就是基于核技巧对线性降维方法进行 _核化_。  

## 10.5 流形学习

一类借鉴了拓扑流形概念的降维方法。 _流形_ 是局部与欧式空间同胚的空间。流形学习可用于可视化。  

### 10.5.1 等度量映射

### 10.5.2 局部线性嵌入

## 10.6 度量学习

度量学习的基本动机：学习出一个合适的距离度量。  

---

# 第11章 特征选择与稀疏学习

## 11.1 子集搜索与评价

从给定的特征集合中选择出相关特征子集的过程，称为 _特征选择_。  

* 子集搜索
* 子集评价

## 11.2 过滤式选择

过滤式方法先对数据集进行特征选择，然后再训练学习器。  
Relief是一种著名的过滤式特征选择方法，该方法设计一个 _相关统计量_ 来度量特征的重要性。  

## 11.3 包裹式选择

包裹式特征选择直接把最终将要使用的学习器的性能作为特征子集的评价标准。  
LVW（Las Vegas Wrapper）是一个典型的包裹式特征选择方法。  

## 11.4 嵌入式选择与<img src="https://latex.codecogs.com/gif.latex?L_1"/>正则化

嵌入式特征选择在学习器训练过程中自动地进行了特征选择。  
缓解过拟合问题，引入正则化项。  

## 11.5 稀疏表示与字典学习

稀疏表达形式使得问题线性可分、降低存储负担。考虑如何将普通非稀疏矩阵转化为稀疏表示。  
为普通稠密表达的样本找到合适的字典，将样本转化为合适稀疏表示形式，从而使得学习任务得以简化，称之为 _字典学习_。  

## 11.6 压缩感知

压缩感知分为 _感知测量_ 和 _重构恢复_。  
_感知测量_ 关注如何对原始信号进行处理获得稀疏样本表示。  
_重构恢复_ 关注是如何基于稀疏性从少量观测中恢复原信号。  

---

# 第12章 计算学习理论

## 12.1 基础知识

几个常用不等式：  

* Jensen不等式
* Hoeffding不等式
* McDiarmid不等式

## 12.2 PAC学习

计算学习理论中基本的是概率近似正确（Probably Approximately Correct，PAC）学习理论。  
令<img src="https://latex.codecogs.com/gif.latex?c"/>表示概念，是从样本空间<img src="https://latex.codecogs.com/gif.latex?\mathcal{X}"/>到标记空间<img src="https://latex.codecogs.com/gif.latex?\mathcal{Y}"/>的映射，它决定示例<img src="https://latex.codecogs.com/gif.latex?\vec{x}"/>的真实标记<img src="https://latex.codecogs.com/gif.latex?y"/>，若对任何样例<img src="https://latex.codecogs.com/gif.latex?(\vec{x},y)"/>有<img src="https://latex.codecogs.com/gif.latex?c(\vec{x})=y"/>成立。则称$c$为目标概念。  
我们希望学得的目标概念所构成的集合称为 _概念类_，用符号<img src="https://latex.codecogs.com/gif.latex?\mathcal{C}"/>表示。  
给定学习算法<img src="https://latex.codecogs.com/gif.latex?\mathfrak{L}"/>，它所考虑的所有可能概念的集合称为 _假设空间_，用符号<img src="https://latex.codecogs.com/gif.latex?\mathcal{H}"/>表示。  
__定义 PAC辨识__：对<img src="https://latex.codecogs.com/gif.latex?0<\epsilon,\delta<1"/>，所有<img src="https://latex.codecogs.com/gif.latex?c\in\mathcal{C}"/>和分布<img src="https://latex.codecogs.com/gif.latex?\mathcal{D}"/>，若存在学习算法<img src="https://latex.codecogs.com/gif.latex?\mathfrak{L}"/>，其输出假设<img src="https://latex.codecogs.com/gif.latex?h\in\mathcal{H}"/>满足  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?P(E(h)\leq\epsilon)\geq1-\delta"/></div> <br>

则称学习算法<img src="https://latex.codecogs.com/gif.latex?\mathfrak{L}"/>能从假设空间<img src="https://latex.codecogs.com/gif.latex?\mathcal{H}"/>中PAC辨别概念类<img src="https://latex.codecogs.com/gif.latex?\mathcal{C}"/>。  
__定义 PAC可学习__  
__定义 PAC学习算法__  
__定义 样本复杂度__  

## 12.3 有限假设空间

### 12.3.1 可分情形

目标概念<img src="https://latex.codecogs.com/gif.latex?c"/>属于假设空间<img src="https://latex.codecogs.com/gif.latex?\mathcal{H}"/>，即<img src="https://latex.codecogs.com/gif.latex?c\in\mathcal{H}"/>。  
只需保留与D一致的的假设，剔除与D不一致的假设，训练集D足够大的情况下，直到<img src="https://latex.codecogs.com/gif.latex?\mathcal{H}"/>中仅剩一个假设为止，这个假设就是目标概念$c$。  

### 12.3.2 不可分情形

对较复杂的学习问题，目标概念<img src="https://latex.codecogs.com/gif.latex?c"/>往往不存在于假设空间<img src="https://latex.codecogs.com/gif.latex?\mathcal{H}"/>中。  
<img src="https://latex.codecogs.com/gif.latex?\mathcal{H}"/>中的任意一个假设都会在训练集上出现或多或少的错误。  
__不可知PAC可学习__  

## 12.4 VC维

_增长函数_：增长函数<img src="https://latex.codecogs.com/gif.latex?\prod_{\mathcal{H}}(m)"/>表示假设空间<img src="https://latex.codecogs.com/gif.latex?\mathcal{H}"/>对m个示例能赋予的最大可能结果数。  
_对分_：对二分类问题而言，<img src="https://latex.codecogs.com/gif.latex?\mathcal{H}"/>中的假设对D中示例赋予标记的每种可能结果称为对D的一种 _对分_。  
_打散_：若假设空间<img src="https://latex.codecogs.com/gif.latex?\mathcal{H}"/>能实现示例集D上的所有对分，即<img src="https://latex.codecogs.com/gif.latex?\prod_{\mathcal{H}}(m)=2^m"/>，则称示例集D能够被假设空间<img src="https://latex.codecogs.com/gif.latex?\mathcal{H}"/> _打散_。  
假设空间<img src="https://latex.codecogs.com/gif.latex?\mathcal{H}"/>的VC维是能够被<img src="https://latex.codecogs.com/gif.latex?\mathcal{H}"/>打散的最大示例集大小。  

## 12.5 Rademacher复杂度

另外一种刻画空间复杂度的途径，在一定程度上考虑了数据分布。  

## 12.6 稳定性

考察算法在输入发生变化时，输出是否随之发生较大变化。  

---

# 第13章 半监督学习

## 13.1 未标记样本

让学习器不依赖外界交互、自动地利用未标记样本来提升学习性能，就是半监督学习。  
要利用为标记样本，要做一些将未标记样本所揭示的数据分布信息与类别标记相联系的假设。_聚类假设_ 与 _流形假设_。  
半监督学习进一步划分为纯半监督学习和直推学习。  

## 13.2 生成式方法

基于生成模型的方法。此类方法假设所有数据都由同一个潜在的模型生成。  

## 13.3 半监督SVM

S3VM是支持向量机在半监督学习上的推广。  

## 13.4 图半监督学习

将数据集映射为一个图，数据集中每个样本对应于图中的一个结点，若两个结点间的相似度（相关性）很高，则对应结点之间存在一条边。边的长度正比于相似度。  

## 13.5 基于分歧的方法

基于分歧的方法使用多学习器，而学习器之间的分歧对未标记数据的利用至关重要。  
_协同训练_ 是此类方法的重要代表，最初针对多视图数据设计的，也被视为多视图学习的代表。  
一个数据对象的一个属性集构成了一个视图。  

## 13.6 半监督聚类

聚类任务中获得的监督信息大致有两种：  

1. _必连_ 与 _勿连_ 约束，前者指样本必属于同一个簇，后者指样本必不属于一个簇。  
2. 监督信息则是少量的标记样本。

---

# 第14章 概率图模型

## 14.1 隐马尔可夫模型

_概率图模型_ 是一类利用图来表达变量相关关系的概率模型。  
第一类使用有向无环图来表示变量间的依赖关系，称为有向图模型或贝叶斯网。  
第二类使用无向图表示变量间的相关关系，称为无向图模型或马尔可夫网。  
_隐马尔可夫模型_ 是结构最简单的动态贝叶斯网。  

## 14.2 马尔可夫随机场

_马尔可夫随机场_ 是典型的马尔可夫网，这是一种著名的无向图模型。  
图中每个结点表示一个或一组变量，结点之间的边表示两个变量之间的依赖关系。  

## 14.3 条件随机场

_条件随机场_ 是一种判别式无向图模型。  
条件随机场视图对多个变量在给定观测值后的条件概率进行建模。  

## 14.4 学习与推断

### 14.4.1 变量消去

精确推断的实质是一类动态规划算法，利用图模型所描述的条件独立性来削减计算目标概率值所需要的计算量。  
变量消去法是最直观的精确推断算法。  

### 14.4.2 信念传播

_信念传播_ 算法将变量消去法中的求和操作看做一个消息传递过程，较好地解决了求解多个边际分布时的重复计算问题。  

## 14.5 近似推断

* _采样_，通过使用随机化方法完成近似
* 使用确定性近似

### 14.5.1 MCMC采样

我们不一定对概率分布本身感兴趣，而是要基于它们计算某些期望。  
通过大量采样，获得对期望的较高的近似。  
概率图模型最常用的采样技术是 _马尔可夫链蒙特卡罗_ （MCMC）方法。  
MCMC方法的关键是构建平稳分布为p的马尔可夫链来产生样本。  
Metropolis-Hastings（MH）算法是MCMC的重要代表。基于 _拒绝采样_ 来逼近平稳分布p。  
吉布斯采样有时也被视为MH算法的特例。  

### 14.5.2 变分推断

变分推断通过使用已知简单分布来逼近需推断的复杂分布，并通过限制近似分布的类型，从而得到一种局部最优、但具有确定解得近似后验分布。  

## 14.6 话题模型

_话题模型_ 是一族生成式有向图模型，主要用于处理离散数据（如文本集合），在信息检索、自然语言处理等领域有广泛的应用。  
_隐狄利克雷分配模型_ （Latent Dirichlet Allocation，LDA）是话题模型的典型代表。  

---

# 第15章 规则学习

## 15.1 基本概念

_规则学习_ 是从训练数据中学习出一组能用于对未见示例进行判别的规则。  
形式地看，一条规则形如：  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?\oplus\gets\bold{f}_1\land\bold{f}_2\land\dots\land\bold{f}_L"/></div> <br>

逻辑蕴含符号“<img src="https://latex.codecogs.com/gif.latex?\gets"/>”右边部分称为 _规则体_，表示该规则的前提；左边部分称为 _规则头_，表示该条规则的结果。  
规则学习有更好的可解释性，数理逻辑具有极强的表达能力。  
当同一个示例被判别结果不同的多条规则覆盖时，称发生了 _冲突_，解决冲突的方法称为 _冲突消解_。投票法、排序法、元规则法。  
规则学习算法通常设置一条 _默认规则_ 来处理规则集合未覆盖的样本。  

## 15.2 序贯覆盖

产生一个能覆盖尽可能多的样例的规则集。最直接的做法是 _序贯覆盖_，即逐条归纳。  
现实任务有两种方法来产生规则：  

* _自顶向下_，从比较一般的规则开始，逐渐添加新文字以缩小规则覆盖范围，直到满足预定条件为止
* _自底向上_，从比较特殊的规则开始，逐渐删除文字以扩大规则覆盖范围，直到满足条件为止

## 15.3 剪枝优化

规则生成本质是一个贪心搜索过程，需要一定的机制来缓解过拟合，常见的做法是剪枝。  
预剪枝与后剪枝。  

## 15.4 一阶规则学习

<div align="center"><img src="https://latex.codecogs.com/gif.latex?更好(X,Y)\gets更好(X,Z)\land更好(Z,Y)"/></div> <br>

## 15.5 归纳逻辑程序设计

_归纳逻辑程序设计_ （Inductive Logic Programming，ILP）在一阶规则学习中引入函数和逻辑表达式嵌套。  
一方面使得机器学习系统具备了更为强大的表达能力；  
另一方面，ILP可看做用机器学习技术解决基于背景知识的逻辑程序归纳。  

### 15.5.1 最小一般泛化

### 15.5.2 逆归结

---

# 第16章 强化学习

## 16.1 任务与奖赏

强化学习任务通常用马尔可夫决策过程来描述：  

> 机器处于环境<img src="https://latex.codecogs.com/gif.latex?E"/>中，状态空间为<img src="https://latex.codecogs.com/gif.latex?X"/>，其中每个状态<img src="https://latex.codecogs.com/gif.latex?x\inX"/>是机器感知到的环境描述；  
> 机器能采取的动作构成了动作空间$A$；  
> 若某个动作<img src="https://latex.codecogs.com/gif.latex?a\inA"/>作用在状态<img src="https://latex.codecogs.com/gif.latex?x"/>上，则潜在的转移函数$P$将使得环境从当前状态以某种概率转移到另一个状态；  
> 在转移到另一个状态的同时，环境会根据潜在的奖赏函数$R$反馈给机器一个奖赏。  

机器要做的是通过在环境中不断尝试而学得一个 _策略_ <img src="https://latex.codecogs.com/gif.latex?\pi"/>，根据这个策略，在状态<img src="https://latex.codecogs.com/gif.latex?x"/>下就能够得知要执行的动作<img src="https://latex.codecogs.com/gif.latex?a=\pi(x)"/>。  
策略有两种表达方法：  
一种是将策略表示为函数<img src="https://latex.codecogs.com/gif.latex?\pi:X\mapstoA"/>，确定性策略常用这种表示；  
另一种是概率表示<img src="https://latex.codecogs.com/gif.latex?\pi:X\timesA\mapsto\R"/>，随机性策略常用这种表示，<img src="https://latex.codecogs.com/gif.latex?\pi(x,a)"/>为状态<img src="https://latex.codecogs.com/gif.latex?x"/>下选择动作<img src="https://latex.codecogs.com/gif.latex?a"/>的概率，必须满足<img src="https://latex.codecogs.com/gif.latex?\sum_a\pi(x,a)=1"/>。  
长期累积奖赏有多种计算方式，常用的有 _T步累积奖赏_ 和 _<img src="https://latex.codecogs.com/gif.latex?\gamma"/>折扣累积奖赏_。  

## 16.2 K-摇臂赌博机

### 16.2.1 探索与利用

__单步强化学习任务__ 对应一个理论模型，_K-摇臂赌博机_（K-armed bandit）。  
_探索_（即估计摇臂的优劣）和 _利用_ （即选择当前最优摇臂）这两者之间是矛盾的，因为尝试次数是有限的，加强一方则会削弱另一方，这就是强化学习面临的 _探索-利用窘境_（Exploration-Exploitation dilemma）。

### 16.2.2 <img src="https://latex.codecogs.com/gif.latex?\epsilon"/>-贪心

<img src="https://latex.codecogs.com/gif.latex?\epsilon"/>-贪心法基于一个概率来对探索和利用进行折中：  
每次尝试时，以<img src="https://latex.codecogs.com/gif.latex?\epsilon"/>的概率进行探索，即以均匀概率随机选取一个摇臂；  
以<img src="https://latex.codecogs.com/gif.latex?1-\epsilon"/>的概率进行利用，即选择当前平均奖赏最高的摇臂（若有多个，则随机选取）。  
__<img src="https://latex.codecogs.com/gif.latex?\epsilon"/>的选取__：  
若摇臂奖赏的不确定性较大，需要较大的<img src="https://latex.codecogs.com/gif.latex?\epsilon"/>值；  
不确定性较小，较小的<img src="https://latex.codecogs.com/gif.latex?\epsilon"/>值；  
<img src="https://latex.codecogs.com/gif.latex?\epsilon"/>的值可能随着尝试次数的增加而减小。  

### 16.2.3 Softmax

Softmax算法基于当前已知的摇臂平均奖赏来对探索和利用进行折中。  

## 16.3 有模型学习

对于 __多步强化学习任务__ ，假定任务对应的马尔可夫决策过程四元组<img src="https://latex.codecogs.com/gif.latex?E=\langle{X,A,P,R}\rangle"/>均为已知，该情形称为 _模型已知_。  
在已知模型的环境中学习称为 _有模型学习_（model-based learning）。

### 16.3.1 策略评估

函数<img src="https://latex.codecogs.com/gif.latex?V^{\pi}(x)"/>表示从状态<img src="https://latex.codecogs.com/gif.latex?x"/>出发，使用策略<img src="https://latex.codecogs.com/gif.latex?\pi"/>能估计出该策略带来的期望累积奖赏。<img src="https://latex.codecogs.com/gif.latex?V(\sdot)"/>称为 _状态值函数_。  
函数<img src="https://latex.codecogs.com/gif.latex?Q^{\pi}(x,a)"/>表示从状态<img src="https://latex.codecogs.com/gif.latex?x"/>出发，执行动作<img src="https://latex.codecogs.com/gif.latex?a"/>后再使用策略<img src="https://latex.codecogs.com/gif.latex?\pi"/>带来的累积奖赏。<img src="https://latex.codecogs.com/gif.latex?Q(\sdot)"/>称为 _状态-动作值函数_。

### 16.3.2 策略改进

关于最优值函数的等式，称为最优Bellman等式，其唯一解是最优值函数。  

### 16.3.3 策略迭代与值迭代

_策略迭代_（policy iteration）：不断迭代进行策略评估和改进，直到策略收敛、不在改变为止。  
策略改进与值函数的改进是一致的，可将策略改进视为值函数的改善。  

## 16.4 免模型学习

学习算法不依赖环境建模，则称为 _免模型学习_（model-free learning）。

### 16.4.1 蒙特卡罗强化学习

蒙特卡罗强化学习：一种直接的策略评估替代方法是多次采样，然后求取平均累积奖赏来作为期望累积奖赏的近似。  
_同策略_（on-policy）蒙特卡罗强化学习算法  
_异策略_（off-policy）蒙特卡罗强化学习算法

### 16.4.2 时序差分学习

时序差分（Temporal Difference，TD）学习则结合动态规划与蒙特卡罗方法的思想，进行高效的免模型学习。  

## 16.5 值函数近似

现实强化学习任务面临的状态空间往往是连续的。  
假设状态空间为<img src="https://latex.codecogs.com/gif.latex?n"/>维实数空间<img src="https://latex.codecogs.com/gif.latex?X=\R^n"/>。考虑简单情形，值函数能表达为状态的线性函数  

<div align="center"><img src="https://latex.codecogs.com/gif.latex?V_{\vec\theta}(\vec{x})={\vec\theta}^T\vec{x}"/></div> <br>

其中<img src="https://latex.codecogs.com/gif.latex?\vec{x}"/>为状态向量，<img src="https://latex.codecogs.com/gif.latex?\vec\theta"/>为参数向量。此时值函数难以像有限状态那样精确记录每个状态的值，称为值函数近似。  

## 16.6 模仿学习

_模仿学习_：从范例中学习

### 16.6.1 直接模仿学习

直接模仿人类专家的 _状态-动作对_ 称为 _直接模仿学习_。  

### 16.6.2 逆强化学习

从人类专家提供的范例数据中反推奖赏函数，就是 _逆强化学习_（inverse reinforcement learning）。  

